{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78a2f407-030f-42ba-8b3b-add892a607d6",
   "metadata": {},
   "source": [
    "# Recommendation Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635c2c5f-d2ef-40d9-b530-1b6888124c6e",
   "metadata": {},
   "source": [
    "*This Jupyter Notebook imports and combines the two datasets (for young adult and children), performs exploratory data analysis, and generates the output for the Recommendation using both collaborative and content-based filtering.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbe788f-a096-4dfb-91e4-32f77e8ff5f9",
   "metadata": {},
   "source": [
    "# Data Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05453a41-a2c6-4a4d-a658-17d5f0e823fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: nltk in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: spacy in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (3.8.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from spacy) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from spacy) (8.3.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from spacy) (0.15.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from spacy) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from spacy) (3.1.3)\n",
      "Requirement already satisfied: setuptools in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from spacy) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from spacy) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.7.4)\n",
      "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.3.5)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from jinja2->spacy) (2.1.3)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.0)\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Requirement already satisfied: sentence-transformers in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (3.4.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (4.49.0)\n",
      "Requirement already satisfied: tqdm in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (1.11.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (0.29.3)\n",
      "Requirement already satisfied: Pillow in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (10.2.0)\n",
      "Requirement already satisfied: filelock in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.7.4)\n",
      "Requirement already satisfied: textstat in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (0.7.5)\n",
      "Requirement already satisfied: pyphen in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from textstat) (0.17.2)\n",
      "Requirement already satisfied: cmudict in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from textstat) (1.0.32)\n",
      "Requirement already satisfied: setuptools in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from textstat) (68.2.2)\n",
      "Requirement already satisfied: importlib-metadata>=5 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from cmudict->textstat) (7.0.1)\n",
      "Requirement already satisfied: importlib-resources>=5 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from cmudict->textstat) (6.5.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from importlib-metadata>=5->cmudict->textstat) (3.17.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas\n",
    "! pip install scikit-learn\n",
    "! pip install nltk\n",
    "! pip install spacy\n",
    "! python -m spacy download en_core_web_sm\n",
    "! pip install sentence-transformers\n",
    "! pip install textstat\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495a2ef2-ac86-4842-98ad-ec95964a0d7a",
   "metadata": {},
   "source": [
    "### API Demo Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d461c2f-afe7-4daa-8fad-ec5c30411cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (2.31.0)\n",
      "Requirement already satisfied: jupyter in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (1.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from requests) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from requests) (2024.7.4)\n",
      "Requirement already satisfied: notebook in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from jupyter) (7.0.8)\n",
      "Requirement already satisfied: qtconsole in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from jupyter) (5.4.2)\n",
      "Requirement already satisfied: jupyter-console in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from jupyter) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from jupyter) (7.10.0)\n",
      "Requirement already satisfied: ipykernel in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from jupyter) (6.28.0)\n",
      "Requirement already satisfied: ipywidgets in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from jupyter) (7.6.5)\n",
      "Requirement already satisfied: appnope in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from ipykernel->jupyter) (0.1.2)\n",
      "Requirement already satisfied: comm>=0.1.1 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from ipykernel->jupyter) (0.1.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from ipykernel->jupyter) (1.6.7)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from ipykernel->jupyter) (8.20.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from ipykernel->jupyter) (8.6.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from ipykernel->jupyter) (5.5.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from ipykernel->jupyter) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from ipykernel->jupyter) (1.6.0)\n",
      "Requirement already satisfied: packaging in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from ipykernel->jupyter) (23.1)\n",
      "Requirement already satisfied: psutil in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from ipykernel->jupyter) (5.9.0)\n",
      "Requirement already satisfied: pyzmq>=24 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from ipykernel->jupyter) (25.1.2)\n",
      "Requirement already satisfied: tornado>=6.1 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from ipykernel->jupyter) (6.3.3)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from ipykernel->jupyter) (5.7.1)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from ipywidgets->jupyter) (0.2.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from ipywidgets->jupyter) (5.9.2)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from ipywidgets->jupyter) (3.5.2)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from ipywidgets->jupyter) (3.0.9)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from jupyter-console->jupyter) (3.0.43)\n",
      "Requirement already satisfied: pygments in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from jupyter-console->jupyter) (2.15.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from nbconvert->jupyter) (4.12.2)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from nbconvert->jupyter) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: jinja2>=3.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from nbconvert->jupyter) (3.1.3)\n",
      "Requirement already satisfied: jupyterlab-pygments in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from nbconvert->jupyter) (0.1.2)\n",
      "Requirement already satisfied: markupsafe>=2.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from nbconvert->jupyter) (2.1.3)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from nbconvert->jupyter) (2.0.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from nbconvert->jupyter) (0.8.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from nbconvert->jupyter) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from nbconvert->jupyter) (1.2.1)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from notebook->jupyter) (2.10.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.22.1 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from notebook->jupyter) (2.25.1)\n",
      "Requirement already satisfied: jupyterlab<4.1,>=4.0.2 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from notebook->jupyter) (4.0.11)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from notebook->jupyter) (0.2.3)\n",
      "Requirement already satisfied: qtpy>=2.0.1 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from qtconsole->jupyter) (2.4.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from bleach!=5.0.0->nbconvert->jupyter) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from bleach!=5.0.0->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: decorator in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.18.1)\n",
      "Requirement already satisfied: stack-data in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (4.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (3.10.0)\n",
      "Requirement already satisfied: anyio>=3.1.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (3.7.1)\n",
      "Requirement already satisfied: argon2-cffi in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (21.3.0)\n",
      "Requirement already satisfied: jupyter-events>=0.6.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (0.8.0)\n",
      "Requirement already satisfied: jupyter-server-terminals in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (0.4.4)\n",
      "Requirement already satisfied: overrides in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (7.4.0)\n",
      "Requirement already satisfied: prometheus-client in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (0.14.1)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (0.17.1)\n",
      "Requirement already satisfied: websocket-client in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (0.58.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from jupyterlab<4.1,>=4.0.2->notebook->jupyter) (2.0.4)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from jupyterlab<4.1,>=4.0.2->notebook->jupyter) (2.2.0)\n",
      "Requirement already satisfied: babel>=2.10 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.22.1->notebook->jupyter) (2.11.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.22.1->notebook->jupyter) (0.9.6)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.22.1->notebook->jupyter) (4.19.2)\n",
      "Requirement already satisfied: fastjsonschema in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from nbformat>=4.2.0->ipywidgets->jupyter) (2.20.0)\n",
      "Requirement already satisfied: wcwidth in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter) (0.2.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from beautifulsoup4->nbconvert->jupyter) (2.5)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (1.3.0)\n",
      "Requirement already satisfied: pytz>=2015.7 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from babel>=2.10->jupyterlab-server<3,>=2.22.1->notebook->jupyter) (2023.3.post1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter) (0.8.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter) (0.10.6)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (2.0.7)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (6.0.1)\n",
      "Requirement already satisfied: rfc3339-validator in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (0.1.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->jupyter) (0.7.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from argon2-cffi->jupyter-server<3,>=2.4.0->notebook->jupyter) (21.2.0)\n",
      "Requirement already satisfied: executing in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter) (0.2.2)\n",
      "Requirement already satisfied: fqdn in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (2.1)\n",
      "Requirement already satisfied: uri-template in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (24.8.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->notebook->jupyter) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->notebook->jupyter) (2.21)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (1.2.3)\n",
      "Requirement already satisfied: Flask in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (2.2.5)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from Flask) (2.2.3)\n",
      "Requirement already satisfied: Jinja2>=3.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from Flask) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from Flask) (2.0.1)\n",
      "Requirement already satisfied: click>=8.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from Flask) (8.1.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/monikanikam/Downloads/new_anaconda/anaconda3/lib/python3.11/site-packages (from Jinja2>=3.0->Flask) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests jupyter\n",
    "! pip install Flask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31fa690a-7688-49d6-882e-f2cc46588d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:7900\n",
      " * Running on http://192.168.1.251:7900\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      " * Restarting with stat\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/monikanikam/Downloads/new_anaconda/anaconda3/envs/book_buddy/lib/python3.11/runpy.py\", line 198, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/monikanikam/Downloads/new_anaconda/anaconda3/envs/book_buddy/lib/python3.11/runpy.py\", line 88, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/monikanikam/Downloads/new_anaconda/anaconda3/envs/book_buddy/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/monikanikam/Downloads/new_anaconda/anaconda3/envs/book_buddy/lib/python3.11/site-packages/traitlets/config/application.py\", line 1074, in launch_instance\n",
      "    app.initialize(argv)\n",
      "  File \"/Users/monikanikam/Downloads/new_anaconda/anaconda3/envs/book_buddy/lib/python3.11/site-packages/traitlets/config/application.py\", line 118, in inner\n",
      "    return method(app, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/monikanikam/Downloads/new_anaconda/anaconda3/envs/book_buddy/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 692, in initialize\n",
      "    self.init_sockets()\n",
      "  File \"/Users/monikanikam/Downloads/new_anaconda/anaconda3/envs/book_buddy/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 331, in init_sockets\n",
      "    self.shell_port = self._bind_socket(self.shell_socket, self.shell_port)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/monikanikam/Downloads/new_anaconda/anaconda3/envs/book_buddy/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 253, in _bind_socket\n",
      "    return self._try_bind_socket(s, port)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/monikanikam/Downloads/new_anaconda/anaconda3/envs/book_buddy/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 229, in _try_bind_socket\n",
      "    s.bind(\"tcp://%s:%i\" % (self.ip, port))\n",
      "  File \"/Users/monikanikam/Downloads/new_anaconda/anaconda3/envs/book_buddy/lib/python3.11/site-packages/zmq/sugar/socket.py\", line 311, in bind\n",
      "    super().bind(addr)\n",
      "  File \"_zmq.py\", line 917, in zmq.backend.cython._zmq.Socket.bind\n",
      "  File \"_zmq.py\", line 179, in zmq.backend.cython._zmq._check_rc\n",
      "zmq.error.ZMQError: Address already in use (addr='tcp://127.0.0.1:51310')\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/monikanikam/Downloads/new_anaconda/anaconda3/envs/book_buddy/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# api.py\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/analyze_sentiment', methods=['POST'])\n",
    "def analyze_sentiment():\n",
    "    analysis_result = \"\"\"\n",
    "Book Sentiment Analysis Summary:\n",
    "================================================================================\n",
    "\n",
    "Total books analyzed: 18\n",
    "\n",
    "Polarity Category Distribution:\n",
    "Extremely Positive: 7 books (38.9%)\n",
    "Very Positive: 4 books (22.2%)\n",
    "Positive: 2 books (11.1%)\n",
    "Neutral: 5 books (27.8%)\n",
    "\n",
    "Top Books with Scores ≥ 0.7 (ordered by review count):\n",
    "- Five Nice Mice Build a House (Score: 0.80, Reviews: 12)\n",
    "- Jinx (Score: 0.80, Reviews: 8)\n",
    "- The Very Hungry Caterpillar (Score: 0.75, Reviews: 7)\n",
    "- What I've Done (Score: 0.83, Reviews: 3)\n",
    "- The Cat in the Hat (Score: 0.72, Reviews: 2)\n",
    "\n",
    "Top Books (combined score & popularity):\n",
    "- Five Nice Mice Build a House (Score: 0.80, Reviews: 12, Combined: 2.97)\n",
    "- Jinx (Score: 0.80, Reviews: 8, Combined: 2.75)\n",
    "- The Very Hungry Caterpillar (Score: 0.75, Reviews: 7, Combined: 2.58)\n",
    "- What I've Done (Score: 0.83, Reviews: 3, Combined: 2.30)\n",
    "- The Cat in the Hat (Score: 0.72, Reviews: 2, Combined: 1.89)\n",
    "\n",
    "Most Negative Books:\n",
    "- The Hostile Hospital (Score: -0.15, Reviews: 1)\n",
    "- Beyond the Grave (Score: -0.25, Reviews: 1)\n",
    "\n",
    "Most Controversial Books (mixed opinions):\n",
    "- Harry Potter and the Order of the Phoenix (Controversy: 0.21, Reviews: 3)\n",
    "- The Giving Tree (Controversy: 0.18, Reviews: 2)\n",
    "- Wonder (Controversy: 0.12, Reviews: 2)\n",
    "- Charlie and the Chocolate Factory (Controversy: 0.00, Reviews: 1)\n",
    "- The Hobbit (Controversy: 0.00, Reviews: 1)\n",
    "\"\"\"\n",
    "    \n",
    "    return analysis_result\n",
    "\n",
    "@app.route('/health', methods=['GET'])\n",
    "def health_check():\n",
    "    return \"API is running\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, host='0.0.0.0', port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22802821-3178-45c4-813c-2fba446a56fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error connecting to API: HTTPConnectionPool(host='localhost', port=5000): Max retries exceeded with url: /analyze_sentiment (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x6a0db5fd0>: Failed to establish a new connection: [Errno 61] Connection refused'))\n"
     ]
    }
   ],
   "source": [
    "# Client code for Jupyter notebook\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def call_sentiment_analysis_api(data=None):\n",
    "    url = \"http://localhost:5000/analyze_sentiment\"\n",
    "    \n",
    "    if data is None:\n",
    "        data = {\n",
    "            \"min_reviews\": 10,\n",
    "            \"prioritize_high_scores\": True\n",
    "        }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, json=data)\n",
    "        if response.status_code == 200:\n",
    "            return response.text\n",
    "        else:\n",
    "            return f\"Error: {response.status_code} - {response.text}\"\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"Error connecting to API: {str(e)}\"\n",
    "\n",
    "sentiment_analysis = call_sentiment_analysis_api()\n",
    "print(sentiment_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b54138b-da4f-4704-afcd-9c44fe09e430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedb6421-46de-46fd-b7b5-f94cb71db3dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3e298ff-6725-42fd-be73-622d2cac1272",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "257ebb4f-9f79-4148-ba7f-927359b8a3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d44fbd0-5263-4d90-b281-d2e56cf79bba",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01acaf0a-4e96-4628-8a87-72466276a34d",
   "metadata": {},
   "source": [
    "From goodreads, we are able to download three sets of data.\n",
    "\n",
    "1. The `books` dataset outlines associated metadata to a specific book. Things of interest here would be `book_id`, `title`, `average_rating`, `ratings_count`,`description`, `num_pages`, `similar_books`, `popular_shelves`. Columns that may be useful, such as `link`, `url`,`image_url`,`authors` and `publishers` will be kept in a separate dataframe and referenced only if needed.\n",
    "2. The `reviews` dataset consists of text reviews that may or may not be added after a rating. As the test reviews do not seem to be useful at this time, we will leave it out. We can consider the data here to scrape for genre.\n",
    "3. The `interactions` dataset indicates whether or not a specific user has read and rated a specific book. It consists of columns `user_id`, `book_id`, `is_read` and `ratings`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0eb1cf-21f2-4d88-bd06-02575b11d476",
   "metadata": {},
   "source": [
    "We have done so for two different age categories (`children` and `young_adult`), and will combine them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ec0cd8-182b-493f-b650-9a21d40f1e9a",
   "metadata": {},
   "source": [
    "### Importing Books Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "321976c3-8bf3-45b6-9938-1a09649ef16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_of_interest = ['book_id', 'title', 'average_rating', 'ratings_count','description', 'num_pages', 'similar_books', 'popular_shelves']\n",
    "json_files = ['goodreads_books_children.json', 'goodreads_books_young_adult.json']\n",
    "data = []\n",
    "\n",
    "for json_file in json_files:\n",
    "    with open(json_file, 'r') as file:\n",
    "        for line in file:\n",
    "            record = json.loads(line)\n",
    "            filtered_record = {key:record[key] for key in columns_of_interest}\n",
    "            data.append(filtered_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915d25e0-1cda-40da-b839-76c45d151ac1",
   "metadata": {},
   "source": [
    "### Filtering Book Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d7d6949-4462-47e3-a431-faab0f4a9e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.DataFrame(data)\n",
    "books['description_length'] = books['description'].apply(len)\n",
    "books = books[books['description_length'] != 0] #filtering empty descriptions\n",
    "books = books.drop('description_length', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d6499be-a34a-484c-b0cc-4b61bf1c4282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>title</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>description</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>similar_books</th>\n",
       "      <th>popular_shelves</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>287141</td>\n",
       "      <td>The Aeneid for Boys and Girls</td>\n",
       "      <td>4.13</td>\n",
       "      <td>46</td>\n",
       "      <td>Relates in vigorous prose the tale of Aeneas, ...</td>\n",
       "      <td>162</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'count': '56', 'name': 'to-read'}, {'count':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6066812</td>\n",
       "      <td>All's Fairy in Love and War (Avalon: Web of Ma...</td>\n",
       "      <td>4.22</td>\n",
       "      <td>98</td>\n",
       "      <td>To Kara's astonishment, she discovers that a p...</td>\n",
       "      <td>216</td>\n",
       "      <td>[948696, 439885, 274955, 12978730, 372986, 216...</td>\n",
       "      <td>[{'count': '515', 'name': 'to-read'}, {'count'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89378</td>\n",
       "      <td>Dog Heaven</td>\n",
       "      <td>4.43</td>\n",
       "      <td>1331</td>\n",
       "      <td>In Newbery Medalist Cynthia Rylant's classic b...</td>\n",
       "      <td>40</td>\n",
       "      <td>[834493, 452189, 140185, 1897316, 2189812, 424...</td>\n",
       "      <td>[{'count': '450', 'name': 'to-read'}, {'count'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1698376</td>\n",
       "      <td>What Do You Do?</td>\n",
       "      <td>3.57</td>\n",
       "      <td>23</td>\n",
       "      <td>WHAT DO YOU DO?\\nA hen lays eggs...\\nA cow giv...</td>\n",
       "      <td>24</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'count': '8', 'name': 'to-read'}, {'count': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2592648</td>\n",
       "      <td>It's Funny Where Ben's Train Takes Him</td>\n",
       "      <td>3.68</td>\n",
       "      <td>21</td>\n",
       "      <td>Ben draws a train that takes him to all sorts ...</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'count': '10', 'name': 'to-read'}, {'count':...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id                                              title average_rating  \\\n",
       "0   287141                      The Aeneid for Boys and Girls           4.13   \n",
       "1  6066812  All's Fairy in Love and War (Avalon: Web of Ma...           4.22   \n",
       "2    89378                                         Dog Heaven           4.43   \n",
       "4  1698376                                    What Do You Do?           3.57   \n",
       "5  2592648             It's Funny Where Ben's Train Takes Him           3.68   \n",
       "\n",
       "  ratings_count                                        description num_pages  \\\n",
       "0            46  Relates in vigorous prose the tale of Aeneas, ...       162   \n",
       "1            98  To Kara's astonishment, she discovers that a p...       216   \n",
       "2          1331  In Newbery Medalist Cynthia Rylant's classic b...        40   \n",
       "4            23  WHAT DO YOU DO?\\nA hen lays eggs...\\nA cow giv...        24   \n",
       "5            21  Ben draws a train that takes him to all sorts ...             \n",
       "\n",
       "                                       similar_books  \\\n",
       "0                                                 []   \n",
       "1  [948696, 439885, 274955, 12978730, 372986, 216...   \n",
       "2  [834493, 452189, 140185, 1897316, 2189812, 424...   \n",
       "4                                                 []   \n",
       "5                                                 []   \n",
       "\n",
       "                                     popular_shelves  \n",
       "0  [{'count': '56', 'name': 'to-read'}, {'count':...  \n",
       "1  [{'count': '515', 'name': 'to-read'}, {'count'...  \n",
       "2  [{'count': '450', 'name': 'to-read'}, {'count'...  \n",
       "4  [{'count': '8', 'name': 'to-read'}, {'count': ...  \n",
       "5  [{'count': '10', 'name': 'to-read'}, {'count':...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(books.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dc7fe3-da55-419b-bae6-19171179f210",
   "metadata": {},
   "source": [
    "### Importing Interactions Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0426a95-59e6-4cf8-8c64-f9f9db1a82d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_of_interest = ['user_id','book_id','is_read','rating']\n",
    "json_files = ['goodreads_interactions_children.json', 'goodreads_interactions_young_adult.json']\n",
    "data = []\n",
    "\n",
    "for json_file in json_files:\n",
    "    with open(json_file, 'r') as file:\n",
    "        for line in file:\n",
    "            record = json.loads(line)\n",
    "            filtered_record = {key:record[key] for key in columns_of_interest}\n",
    "            data.append(filtered_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dbbb53-8530-4996-8acc-02d1798f058f",
   "metadata": {},
   "source": [
    "### Filtering Interactions Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87a62b60-9cbf-4f83-9b80-0d6f1d72cecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = pd.DataFrame(data)\n",
    "interactions = interactions[interactions['is_read'] != 0] #removing ratings by people who have not read the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca800bbb-8c26-4b64-a460-8e8577f95202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>is_read</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
       "      <td>23310161</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
       "      <td>18296097</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
       "      <td>817720</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
       "      <td>502362</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
       "      <td>1969280</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            user_id   book_id  is_read  rating\n",
       "5  8842281e1d1347389f2ab93d60773d4d  23310161     True       4\n",
       "6  8842281e1d1347389f2ab93d60773d4d  18296097     True       5\n",
       "7  8842281e1d1347389f2ab93d60773d4d    817720     True       5\n",
       "8  8842281e1d1347389f2ab93d60773d4d    502362     True       5\n",
       "9  8842281e1d1347389f2ab93d60773d4d   1969280     True       5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(interactions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b93955-7020-4bfc-a7ad-7470c0af6e1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27367c62-568a-4847-b3d7-264d09278f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_text</th>\n",
       "      <th>date_added</th>\n",
       "      <th>date_updated</th>\n",
       "      <th>read_at</th>\n",
       "      <th>started_at</th>\n",
       "      <th>n_votes</th>\n",
       "      <th>n_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
       "      <td>23310161</td>\n",
       "      <td>f4b4b050f4be00e9283c92a814af2670</td>\n",
       "      <td>4</td>\n",
       "      <td>Fun sequel to the original.</td>\n",
       "      <td>Tue Nov 17 11:37:35 -0800 2015</td>\n",
       "      <td>Tue Nov 17 11:38:05 -0800 2015</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
       "      <td>17290220</td>\n",
       "      <td>22d424a2b0057b18fb6ecf017af7be92</td>\n",
       "      <td>5</td>\n",
       "      <td>One of my favorite books to read to my 5 year ...</td>\n",
       "      <td>Sat Nov 08 08:54:03 -0800 2014</td>\n",
       "      <td>Wed Jan 25 13:56:12 -0800 2017</td>\n",
       "      <td>Tue Jan 24 00:00:00 -0800 2017</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
       "      <td>6954929</td>\n",
       "      <td>50ed4431c451d5677d98dd25ca8ec106</td>\n",
       "      <td>5</td>\n",
       "      <td>One of the best and most imaginative childrens...</td>\n",
       "      <td>Thu Oct 23 13:46:20 -0700 2014</td>\n",
       "      <td>Thu Oct 23 13:47:00 -0700 2014</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
       "      <td>460548</td>\n",
       "      <td>1e4de11dd4fa4b7ffa59b6c69a6b28e9</td>\n",
       "      <td>5</td>\n",
       "      <td>My daughter is loving this. Published in the 6...</td>\n",
       "      <td>Mon Dec 02 10:43:59 -0800 2013</td>\n",
       "      <td>Wed Mar 22 11:47:25 -0700 2017</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
       "      <td>11474551</td>\n",
       "      <td>2065145714bf747083a1c9ce81d5c4fe</td>\n",
       "      <td>5</td>\n",
       "      <td>A friend sent me this. Hilarious!</td>\n",
       "      <td>Wed May 11 22:38:11 -0700 2011</td>\n",
       "      <td>Sun Jan 29 15:56:41 -0800 2012</td>\n",
       "      <td>Wed May 11 00:00:00 -0700 2011</td>\n",
       "      <td>Wed May 11 00:00:00 -0700 2011</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            user_id   book_id  \\\n",
       "0  8842281e1d1347389f2ab93d60773d4d  23310161   \n",
       "1  8842281e1d1347389f2ab93d60773d4d  17290220   \n",
       "2  8842281e1d1347389f2ab93d60773d4d   6954929   \n",
       "3  8842281e1d1347389f2ab93d60773d4d    460548   \n",
       "4  8842281e1d1347389f2ab93d60773d4d  11474551   \n",
       "\n",
       "                          review_id  rating  \\\n",
       "0  f4b4b050f4be00e9283c92a814af2670       4   \n",
       "1  22d424a2b0057b18fb6ecf017af7be92       5   \n",
       "2  50ed4431c451d5677d98dd25ca8ec106       5   \n",
       "3  1e4de11dd4fa4b7ffa59b6c69a6b28e9       5   \n",
       "4  2065145714bf747083a1c9ce81d5c4fe       5   \n",
       "\n",
       "                                         review_text  \\\n",
       "0                        Fun sequel to the original.   \n",
       "1  One of my favorite books to read to my 5 year ...   \n",
       "2  One of the best and most imaginative childrens...   \n",
       "3  My daughter is loving this. Published in the 6...   \n",
       "4                  A friend sent me this. Hilarious!   \n",
       "\n",
       "                       date_added                    date_updated  \\\n",
       "0  Tue Nov 17 11:37:35 -0800 2015  Tue Nov 17 11:38:05 -0800 2015   \n",
       "1  Sat Nov 08 08:54:03 -0800 2014  Wed Jan 25 13:56:12 -0800 2017   \n",
       "2  Thu Oct 23 13:46:20 -0700 2014  Thu Oct 23 13:47:00 -0700 2014   \n",
       "3  Mon Dec 02 10:43:59 -0800 2013  Wed Mar 22 11:47:25 -0700 2017   \n",
       "4  Wed May 11 22:38:11 -0700 2011  Sun Jan 29 15:56:41 -0800 2012   \n",
       "\n",
       "                          read_at                      started_at  n_votes  \\\n",
       "0                                                                        7   \n",
       "1  Tue Jan 24 00:00:00 -0800 2017                                        4   \n",
       "2                                                                        6   \n",
       "3                                                                        5   \n",
       "4  Wed May 11 00:00:00 -0700 2011  Wed May 11 00:00:00 -0700 2011        5   \n",
       "\n",
       "   n_comments  \n",
       "0           0  \n",
       "1           0  \n",
       "2           1  \n",
       "3           4  \n",
       "4           0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "json_files = ['goodreads_reviews_children.json', 'goodreads_reviews_young_adult.json']\n",
    "data = []\n",
    "\n",
    "for json_file in json_files:\n",
    "    with open(json_file, 'r') as file:\n",
    "        for line in file:\n",
    "            record = json.loads(line)\n",
    "            data.append(record)\n",
    "review_df = pd.DataFrame(data)\n",
    "review_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac4d8c0f-fcb9-43ed-b873-659c3a2d0840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_books_and_reviews(books_df, reviews_df):\n",
    "    books_df_copy = books_df.copy()\n",
    "    reviews_df_copy = reviews_df.copy()\n",
    "    \n",
    "    books_df_copy['book_id'] = books_df_copy['book_id'].astype(str)\n",
    "    reviews_df_copy['book_id'] = reviews_df_copy['book_id'].astype(str)\n",
    "    \n",
    "    combined_df = reviews_df_copy.merge(books_df_copy, on='book_id', how='left')\n",
    "    \n",
    "    print(f\"Combined data shape: {combined_df.shape}\")\n",
    "    print(f\"Number of unique books: {combined_df['book_id'].nunique()}\")\n",
    "    print(f\"Number of unique users: {combined_df['user_id'].nunique()}\")\n",
    "    \n",
    "    missing_books = reviews_df_copy[~reviews_df_copy['book_id'].isin(books_df_copy['book_id'])]\n",
    "    print(f\"Reviews with missing book data: {len(missing_books)} ({len(missing_books)/len(reviews_df_copy)*100:.2f}%)\")\n",
    "    \n",
    "    return combined_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81d28e68-c69a-41cc-9a74-b694b79711f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data shape: (3171054, 18)\n",
      "Number of unique books: 214550\n",
      "Number of unique users: 233167\n",
      "Reviews with missing book data: 66565 (2.13%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_text</th>\n",
       "      <th>date_added</th>\n",
       "      <th>date_updated</th>\n",
       "      <th>read_at</th>\n",
       "      <th>started_at</th>\n",
       "      <th>n_votes</th>\n",
       "      <th>n_comments</th>\n",
       "      <th>title</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>description</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>similar_books</th>\n",
       "      <th>popular_shelves</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
       "      <td>23310161</td>\n",
       "      <td>f4b4b050f4be00e9283c92a814af2670</td>\n",
       "      <td>4</td>\n",
       "      <td>Fun sequel to the original.</td>\n",
       "      <td>Tue Nov 17 11:37:35 -0800 2015</td>\n",
       "      <td>Tue Nov 17 11:38:05 -0800 2015</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>The Day the Crayons Came Home</td>\n",
       "      <td>4.43</td>\n",
       "      <td>8924</td>\n",
       "      <td>The companion to the #1 blockbuster bestseller...</td>\n",
       "      <td>36</td>\n",
       "      <td>[22249668, 25745002, 23309640, 23735067, 20518...</td>\n",
       "      <td>[{'count': '2078', 'name': 'to-read'}, {'count...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
       "      <td>17290220</td>\n",
       "      <td>22d424a2b0057b18fb6ecf017af7be92</td>\n",
       "      <td>5</td>\n",
       "      <td>One of my favorite books to read to my 5 year ...</td>\n",
       "      <td>Sat Nov 08 08:54:03 -0800 2014</td>\n",
       "      <td>Wed Jan 25 13:56:12 -0800 2017</td>\n",
       "      <td>Tue Jan 24 00:00:00 -0800 2017</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Rosie Revere, Engineer</td>\n",
       "      <td>4.54</td>\n",
       "      <td>4789</td>\n",
       "      <td>Rosie may seem quiet during the day, but at ni...</td>\n",
       "      <td>32</td>\n",
       "      <td>[18383325, 13722312, 17684972, 17245740, 16002...</td>\n",
       "      <td>[{'count': '2317', 'name': 'to-read'}, {'count...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
       "      <td>6954929</td>\n",
       "      <td>50ed4431c451d5677d98dd25ca8ec106</td>\n",
       "      <td>5</td>\n",
       "      <td>One of the best and most imaginative childrens...</td>\n",
       "      <td>Thu Oct 23 13:46:20 -0700 2014</td>\n",
       "      <td>Thu Oct 23 13:47:00 -0700 2014</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>Zoom</td>\n",
       "      <td>4.67</td>\n",
       "      <td>33</td>\n",
       "      <td>Michele Landsberg wrote of the first Zoom book...</td>\n",
       "      <td>96</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'count': '30', 'name': 'to-read'}, {'count':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
       "      <td>460548</td>\n",
       "      <td>1e4de11dd4fa4b7ffa59b6c69a6b28e9</td>\n",
       "      <td>5</td>\n",
       "      <td>My daughter is loving this. Published in the 6...</td>\n",
       "      <td>Mon Dec 02 10:43:59 -0800 2013</td>\n",
       "      <td>Wed Mar 22 11:47:25 -0700 2017</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Go, Dog. Go!</td>\n",
       "      <td>4.08</td>\n",
       "      <td>67048</td>\n",
       "      <td>Reading goes to the dogs in this timeless Begi...</td>\n",
       "      <td>72</td>\n",
       "      <td>[206962, 488908, 260996, 7797, 2121669, 24688,...</td>\n",
       "      <td>[{'count': '4441', 'name': 'to-read'}, {'count...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
       "      <td>11474551</td>\n",
       "      <td>2065145714bf747083a1c9ce81d5c4fe</td>\n",
       "      <td>5</td>\n",
       "      <td>A friend sent me this. Hilarious!</td>\n",
       "      <td>Wed May 11 22:38:11 -0700 2011</td>\n",
       "      <td>Sun Jan 29 15:56:41 -0800 2012</td>\n",
       "      <td>Wed May 11 00:00:00 -0700 2011</td>\n",
       "      <td>Wed May 11 00:00:00 -0700 2011</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Go the Fuck to Sleep</td>\n",
       "      <td>4.26</td>\n",
       "      <td>309</td>\n",
       "      <td>Go the Fuck to Sleepis a bedtime book for pare...</td>\n",
       "      <td>32</td>\n",
       "      <td>[8044557, 7747422, 8687916, 58094, 6465483, 10...</td>\n",
       "      <td>[{'count': '5062', 'name': 'to-read'}, {'count...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            user_id   book_id  \\\n",
       "0  8842281e1d1347389f2ab93d60773d4d  23310161   \n",
       "1  8842281e1d1347389f2ab93d60773d4d  17290220   \n",
       "2  8842281e1d1347389f2ab93d60773d4d   6954929   \n",
       "3  8842281e1d1347389f2ab93d60773d4d    460548   \n",
       "4  8842281e1d1347389f2ab93d60773d4d  11474551   \n",
       "\n",
       "                          review_id  rating  \\\n",
       "0  f4b4b050f4be00e9283c92a814af2670       4   \n",
       "1  22d424a2b0057b18fb6ecf017af7be92       5   \n",
       "2  50ed4431c451d5677d98dd25ca8ec106       5   \n",
       "3  1e4de11dd4fa4b7ffa59b6c69a6b28e9       5   \n",
       "4  2065145714bf747083a1c9ce81d5c4fe       5   \n",
       "\n",
       "                                         review_text  \\\n",
       "0                        Fun sequel to the original.   \n",
       "1  One of my favorite books to read to my 5 year ...   \n",
       "2  One of the best and most imaginative childrens...   \n",
       "3  My daughter is loving this. Published in the 6...   \n",
       "4                  A friend sent me this. Hilarious!   \n",
       "\n",
       "                       date_added                    date_updated  \\\n",
       "0  Tue Nov 17 11:37:35 -0800 2015  Tue Nov 17 11:38:05 -0800 2015   \n",
       "1  Sat Nov 08 08:54:03 -0800 2014  Wed Jan 25 13:56:12 -0800 2017   \n",
       "2  Thu Oct 23 13:46:20 -0700 2014  Thu Oct 23 13:47:00 -0700 2014   \n",
       "3  Mon Dec 02 10:43:59 -0800 2013  Wed Mar 22 11:47:25 -0700 2017   \n",
       "4  Wed May 11 22:38:11 -0700 2011  Sun Jan 29 15:56:41 -0800 2012   \n",
       "\n",
       "                          read_at                      started_at  n_votes  \\\n",
       "0                                                                        7   \n",
       "1  Tue Jan 24 00:00:00 -0800 2017                                        4   \n",
       "2                                                                        6   \n",
       "3                                                                        5   \n",
       "4  Wed May 11 00:00:00 -0700 2011  Wed May 11 00:00:00 -0700 2011        5   \n",
       "\n",
       "   n_comments                          title average_rating ratings_count  \\\n",
       "0           0  The Day the Crayons Came Home           4.43          8924   \n",
       "1           0         Rosie Revere, Engineer           4.54          4789   \n",
       "2           1                           Zoom           4.67            33   \n",
       "3           4                   Go, Dog. Go!           4.08         67048   \n",
       "4           0           Go the Fuck to Sleep           4.26           309   \n",
       "\n",
       "                                         description num_pages  \\\n",
       "0  The companion to the #1 blockbuster bestseller...        36   \n",
       "1  Rosie may seem quiet during the day, but at ni...        32   \n",
       "2  Michele Landsberg wrote of the first Zoom book...        96   \n",
       "3  Reading goes to the dogs in this timeless Begi...        72   \n",
       "4  Go the Fuck to Sleepis a bedtime book for pare...        32   \n",
       "\n",
       "                                       similar_books  \\\n",
       "0  [22249668, 25745002, 23309640, 23735067, 20518...   \n",
       "1  [18383325, 13722312, 17684972, 17245740, 16002...   \n",
       "2                                                 []   \n",
       "3  [206962, 488908, 260996, 7797, 2121669, 24688,...   \n",
       "4  [8044557, 7747422, 8687916, 58094, 6465483, 10...   \n",
       "\n",
       "                                     popular_shelves  \n",
       "0  [{'count': '2078', 'name': 'to-read'}, {'count...  \n",
       "1  [{'count': '2317', 'name': 'to-read'}, {'count...  \n",
       "2  [{'count': '30', 'name': 'to-read'}, {'count':...  \n",
       "3  [{'count': '4441', 'name': 'to-read'}, {'count...  \n",
       "4  [{'count': '5062', 'name': 'to-read'}, {'count...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_review_df= combine_books_and_reviews(books, review_df)\n",
    "book_review_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e535cef-06f7-45ff-b2a4-2f1bc5350bdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e44f5fc0-875f-4399-a3c3-a31e430978dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36354 books with at least 10 reviews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/3m8q3qpj07gck8tzw0d070tm0000gn/T/ipykernel_31970/1005594093.py:32: RuntimeWarning: divide by zero encountered in log1p\n",
      "  vote_weight = np.log1p(n_votes)\n",
      "/var/folders/7g/3m8q3qpj07gck8tzw0d070tm0000gn/T/ipykernel_31970/1005594093.py:32: RuntimeWarning: invalid value encountered in log1p\n",
      "  vote_weight = np.log1p(n_votes)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Book Sentiment Analysis Summary:\n",
      "================================================================================\n",
      "\n",
      "Total books analyzed: 36354\n",
      "\n",
      "Polarity Category Distribution:\n",
      "Positive: 25154 books (69.2%)\n",
      "Very Positive: 9604 books (26.4%)\n",
      "Neutral: 1483 books (4.1%)\n",
      "Very Negative: 113 books (0.3%)\n",
      "\n",
      "Top Books (by positivity and popularity):\n",
      "- Wonder (Wonder #1) (Score: 0.44, Reviews: 15878, Combined: 1.30)\n",
      "- The Giver (The Giver, #1) (Score: 0.46, Reviews: 6155, Combined: 1.27)\n",
      "- Harry Potter and the Prisoner of Azkaban (Harry Potter, #3) (Score: 0.46, Reviews: 4696, Combined: 1.25)\n",
      "- Catching Fire (The Hunger Games, #2) (Score: 0.44, Reviews: 8738, Combined: 1.23)\n",
      "- Holes (Holes, #1) (Score: 0.45, Reviews: 5074, Combined: 1.23)\n",
      "\n",
      "Most Negative Books:\n",
      "- The Sky Throne (Score: -0.00, Reviews: 10)\n",
      "- Headlong (Score: -0.01, Reviews: 11)\n",
      "- The Charm (Olivia Hart and the Gifted Program, #1) (Score: -0.02, Reviews: 4)\n",
      "- The Shadow of the Bear (A Fairy Tale Retold #1) (Score: -0.02, Reviews: 8)\n",
      "- Beyond the Dead Forest (Score: -0.02, Reviews: 9)\n",
      "\n",
      "Most Controversial Books (mixed opinions):\n",
      "- A Blade So Black (Controversy: 2.12, Reviews: 13)\n",
      "- When I Wake (Controversy: 2.07, Reviews: 7)\n",
      "- That Night's Train (Controversy: 1.77, Reviews: 10)\n",
      "- Children of Blood and Bone (Controversy: 1.72, Reviews: 30)\n",
      "- To Kill a Kingdom (Controversy: 1.72, Reviews: 11)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "\n",
    "def analyze_review_polarity(combined_df):\n",
    "    if len(combined_df) == 0:\n",
    "        print(\"Warning: Empty dataframe provided\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    try:\n",
    "        nltk.download('vader_lexicon', quiet=True)\n",
    "    except:\n",
    "        print(\"Failed to download VADER lexicon, but continuing...\")\n",
    "    \n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    def get_review_sentiment(row):\n",
    "        review_text = str(row.get('review_text', '')) if not pd.isna(row.get('review_text')) else ''\n",
    "        sentiment_scores = sia.polarity_scores(review_text)\n",
    "        compound_score = sentiment_scores['compound']\n",
    "        \n",
    "        try:\n",
    "            rating = float(row.get('rating', 0)) if not pd.isna(row.get('rating')) else 0\n",
    "            rating_weight = (rating - 3) / 2\n",
    "        except:\n",
    "            rating_weight = 0\n",
    "        \n",
    "        try:\n",
    "            n_votes = int(row.get('n_votes', 0)) if not pd.isna(row.get('n_votes')) else 0\n",
    "            vote_weight = np.log1p(n_votes)\n",
    "        except:\n",
    "            vote_weight = 0\n",
    "        \n",
    "        max_vote_weight = 5\n",
    "        normalized_vote_weight = min(vote_weight / max_vote_weight, 1)\n",
    "        \n",
    "        weighted_score = (0.6 * compound_score) + (0.3 * rating_weight) + (0.1 * normalized_vote_weight)\n",
    "        \n",
    "        return {\n",
    "            'text_sentiment': compound_score,\n",
    "            'rating_sentiment': rating_weight,\n",
    "            'vote_weight': normalized_vote_weight,\n",
    "            'weighted_score': weighted_score\n",
    "        }\n",
    "    \n",
    "    combined_df_clean = combined_df.copy()\n",
    "    \n",
    "    for col in ['rating', 'n_votes', 'review_text']:\n",
    "        if col in combined_df_clean.columns:\n",
    "            combined_df_clean[col] = combined_df_clean[col].fillna(0)\n",
    "    \n",
    "    sentiment_results = combined_df_clean.apply(get_review_sentiment, axis=1)\n",
    "    sentiment_df = pd.DataFrame(sentiment_results.tolist())\n",
    "    \n",
    "    enhanced_df = pd.concat([combined_df_clean, sentiment_df], axis=1)\n",
    "    \n",
    "    if 'book_id' not in enhanced_df.columns:\n",
    "        print(\"Error: book_id column missing from dataframe\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    if len(enhanced_df['book_id'].unique()) == 0:\n",
    "        print(\"Error: No unique book_ids found\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    agg_dict = {}\n",
    "    \n",
    "    if 'title' in enhanced_df.columns:\n",
    "        agg_dict['title'] = 'first'\n",
    "    \n",
    "    for col in ['weighted_score', 'text_sentiment', 'rating_sentiment']:\n",
    "        if col in enhanced_df.columns:\n",
    "            agg_dict[col] = ['mean', 'count', 'std']\n",
    "    \n",
    "    if 'rating' in enhanced_df.columns:\n",
    "        agg_dict['rating'] = ['mean', 'count', 'std']\n",
    "    \n",
    "    if 'n_votes' in enhanced_df.columns:\n",
    "        agg_dict['n_votes'] = ['sum', 'mean']\n",
    "    \n",
    "    book_polarity = enhanced_df.groupby('book_id').agg(agg_dict)\n",
    "    \n",
    "    book_polarity.columns = ['_'.join(col).strip() for col in book_polarity.columns.values]\n",
    "    \n",
    "    def get_polarity_category(score):\n",
    "        if score >= 0.5:\n",
    "            return \"Very Positive\"\n",
    "        elif score >= 0.25:\n",
    "            return \"Positive\"\n",
    "        elif score >= -0.25:\n",
    "            return \"Neutral\"\n",
    "        elif score >= -0.5:\n",
    "            return \"Negative\"\n",
    "        else:\n",
    "            return \"Very Negative\"\n",
    "    \n",
    "    if 'weighted_score_mean' in book_polarity.columns:\n",
    "        book_polarity['polarity_category'] = book_polarity['weighted_score_mean'].apply(get_polarity_category)\n",
    "    else:\n",
    "        book_polarity['polarity_category'] = \"Unknown\"\n",
    "    \n",
    "    book_polarity = book_polarity.reset_index()\n",
    "    \n",
    "    book_polarity['controversy_score'] = 0\n",
    "    \n",
    "    if 'text_sentiment_std' in book_polarity.columns and 'rating_std' in book_polarity.columns:\n",
    "        book_polarity['controversy_score'] = book_polarity['text_sentiment_std'] * book_polarity['rating_std']\n",
    "    \n",
    "    if 'weighted_score_mean' in book_polarity.columns and 'weighted_score_count' in book_polarity.columns:\n",
    "        book_polarity['popularity_score'] = book_polarity['weighted_score_mean'] * (1 + np.log1p(book_polarity['weighted_score_count']) / 5)\n",
    "        book_polarity = book_polarity.sort_values('popularity_score', ascending=False)\n",
    "    elif 'weighted_score_mean' in book_polarity.columns:\n",
    "        book_polarity = book_polarity.sort_values('weighted_score_mean', ascending=False)\n",
    "    \n",
    "    return book_polarity\n",
    "\n",
    "def display_book_polarity_summary(book_polarity_df):\n",
    "    if len(book_polarity_df) == 0:\n",
    "        print(\"No books to analyze\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\nBook Sentiment Analysis Summary:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(f\"\\nTotal books analyzed: {len(book_polarity_df)}\")\n",
    "    \n",
    "    if 'polarity_category' in book_polarity_df.columns:\n",
    "        category_counts = book_polarity_df['polarity_category'].value_counts()\n",
    "        print(\"\\nPolarity Category Distribution:\")\n",
    "        for category, count in category_counts.items():\n",
    "            print(f\"{category}: {count} books ({count/len(book_polarity_df)*100:.1f}%)\")\n",
    "    \n",
    "    if 'popularity_score' in book_polarity_df.columns and 'title_first' in book_polarity_df.columns:\n",
    "        print(\"\\nTop Books (by positivity and popularity):\")\n",
    "        top_books = book_polarity_df.head(min(5, len(book_polarity_df)))\n",
    "        for _, book in top_books.iterrows():\n",
    "            review_count = book.get('weighted_score_count', 'N/A')\n",
    "            print(f\"- {book['title_first']} (Score: {book['weighted_score_mean']:.2f}, Reviews: {review_count}, Combined: {book['popularity_score']:.2f})\")\n",
    "    elif 'weighted_score_mean' in book_polarity_df.columns and 'title_first' in book_polarity_df.columns:\n",
    "        print(\"\\nTop Most Positive Books:\")\n",
    "        top_positive = book_polarity_df.head(min(5, len(book_polarity_df)))\n",
    "        for _, book in top_positive.iterrows():\n",
    "            review_count = book.get('weighted_score_count', 'N/A')\n",
    "            print(f\"- {book['title_first']} (Score: {book['weighted_score_mean']:.2f}, Reviews: {review_count})\")\n",
    "    \n",
    "    if 'weighted_score_mean' in book_polarity_df.columns:\n",
    "        negative_books = book_polarity_df[book_polarity_df['weighted_score_mean'] < 0]\n",
    "        if len(negative_books) > 0:\n",
    "            print(\"\\nMost Negative Books:\")\n",
    "            top_negative = negative_books.head(min(5, len(negative_books)))\n",
    "            for _, book in top_negative.iterrows():\n",
    "                review_count = book.get('weighted_score_count', 'N/A')\n",
    "                print(f\"- {book['title_first']} (Score: {book['weighted_score_mean']:.2f}, Reviews: {review_count})\")\n",
    "        else:\n",
    "            print(\"\\nNo books with negative overall sentiment found.\")\n",
    "    \n",
    "    if 'controversy_score' in book_polarity_df.columns and 'title_first' in book_polarity_df.columns:\n",
    "        print(\"\\nMost Controversial Books (mixed opinions):\")\n",
    "        controversial = book_polarity_df.sort_values('controversy_score', ascending=False).head(min(5, len(book_polarity_df)))\n",
    "        for _, book in controversial.iterrows():\n",
    "            review_count = book.get('weighted_score_count', 'N/A')\n",
    "            print(f\"- {book['title_first']} (Controversy: {book['controversy_score']:.2f}, Reviews: {review_count})\")\n",
    "    \n",
    "    return\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        review_counts = book_review_df['book_id'].value_counts()\n",
    "        books_with_min_reviews = review_counts[review_counts >= 10].index\n",
    "        \n",
    "        if len(books_with_min_reviews) == 0:\n",
    "            print(\"No books found with at least 10 reviews\")\n",
    "            max_reviews = review_counts.max()\n",
    "            print(f\"Maximum reviews for any book: {max_reviews}\")\n",
    "            print(\"Using all data instead\")\n",
    "            filtered_df = book_review_df\n",
    "        else:\n",
    "            print(f\"Found {len(books_with_min_reviews)} books with at least 10 reviews\")\n",
    "            filtered_df = book_review_df[book_review_df['book_id'].isin(books_with_min_reviews)]\n",
    "        \n",
    "        book_polarity = analyze_review_polarity(filtered_df)\n",
    "        display_book_polarity_summary(book_polarity)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab655429-bb12-495e-825e-cfacf09d5ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "403dea9f-dadb-4c70-a6ab-9a7268c0d539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36354 books with at least 10 reviews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/3m8q3qpj07gck8tzw0d070tm0000gn/T/ipykernel_31970/2205791924.py:32: RuntimeWarning: divide by zero encountered in log1p\n",
      "  vote_weight = np.log1p(n_votes)\n",
      "/var/folders/7g/3m8q3qpj07gck8tzw0d070tm0000gn/T/ipykernel_31970/2205791924.py:32: RuntimeWarning: invalid value encountered in log1p\n",
      "  vote_weight = np.log1p(n_votes)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Book Sentiment Analysis Summary:\n",
      "================================================================================\n",
      "\n",
      "Total books analyzed: 36354\n",
      "\n",
      "Polarity Category Distribution:\n",
      "Positive: 25154 books (69.2%)\n",
      "Very Positive: 9419 books (25.9%)\n",
      "Neutral: 1483 books (4.1%)\n",
      "Extremely Positive: 185 books (0.5%)\n",
      "Very Negative: 113 books (0.3%)\n",
      "\n",
      "Top Books with Scores ≥ 0.7 (ordered by review count):\n",
      "- Schim en Schaduw (De Grisha, #1) (Score: 0.71, Reviews: 24)\n",
      "- Little Elliot, Big Fun (Score: 0.72, Reviews: 21)\n",
      "- The Kiss That Missed (Score: 0.70, Reviews: 21)\n",
      "- Fangirl (Score: 0.72, Reviews: 19)\n",
      "- Green Pants (Score: 0.76, Reviews: 18)\n",
      "\n",
      "Top Books (combined score & popularity):\n",
      "- Green Pants (Score: 0.76, Reviews: 18, Combined: 3.03)\n",
      "- Five Nice Mice Build a House (Score: 0.80, Reviews: 12, Combined: 2.96)\n",
      "- Schim en Schaduw (De Grisha, #1) (Score: 0.71, Reviews: 24, Combined: 2.96)\n",
      "- The Shepherd's Crown (Discworld, #41; Tiffany Aching, #5) (Score: 0.79, Reviews: 12, Combined: 2.94)\n",
      "- Little Elliot, Big Fun (Score: 0.72, Reviews: 21, Combined: 2.91)\n",
      "\n",
      "Most Negative Books:\n",
      "- The Sky Throne (Score: -0.00, Reviews: 10)\n",
      "- Headlong (Score: -0.01, Reviews: 11)\n",
      "- The Charm (Olivia Hart and the Gifted Program, #1) (Score: -0.02, Reviews: 4)\n",
      "- The Shadow of the Bear (A Fairy Tale Retold #1) (Score: -0.02, Reviews: 8)\n",
      "- Beyond the Dead Forest (Score: -0.02, Reviews: 9)\n",
      "\n",
      "Most Controversial Books (mixed opinions):\n",
      "- A Blade So Black (Controversy: 2.12, Reviews: 13)\n",
      "- When I Wake (Controversy: 2.07, Reviews: 7)\n",
      "- That Night's Train (Controversy: 1.77, Reviews: 10)\n",
      "- Children of Blood and Bone (Controversy: 1.72, Reviews: 30)\n",
      "- To Kill a Kingdom (Controversy: 1.72, Reviews: 11)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "\n",
    "def analyze_review_polarity(combined_df):\n",
    "    if len(combined_df) == 0:\n",
    "        print(\"Warning: Empty dataframe provided\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    try:\n",
    "        nltk.download('vader_lexicon', quiet=True)\n",
    "    except:\n",
    "        print(\"Failed to download VADER lexicon, but continuing...\")\n",
    "    \n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    def get_review_sentiment(row):\n",
    "        review_text = str(row.get('review_text', '')) if not pd.isna(row.get('review_text')) else ''\n",
    "        sentiment_scores = sia.polarity_scores(review_text)\n",
    "        compound_score = sentiment_scores['compound']\n",
    "        \n",
    "        try:\n",
    "            rating = float(row.get('rating', 0)) if not pd.isna(row.get('rating')) else 0\n",
    "            rating_weight = (rating - 3) / 2\n",
    "        except:\n",
    "            rating_weight = 0\n",
    "        \n",
    "        try:\n",
    "            n_votes = int(row.get('n_votes', 0)) if not pd.isna(row.get('n_votes')) else 0\n",
    "            vote_weight = np.log1p(n_votes)\n",
    "        except:\n",
    "            vote_weight = 0\n",
    "        \n",
    "        max_vote_weight = 5\n",
    "        normalized_vote_weight = min(vote_weight / max_vote_weight, 1)\n",
    "        \n",
    "        weighted_score = (0.6 * compound_score) + (0.3 * rating_weight) + (0.1 * normalized_vote_weight)\n",
    "        \n",
    "        return {\n",
    "            'text_sentiment': compound_score,\n",
    "            'rating_sentiment': rating_weight,\n",
    "            'vote_weight': normalized_vote_weight,\n",
    "            'weighted_score': weighted_score\n",
    "        }\n",
    "    \n",
    "    combined_df_clean = combined_df.copy()\n",
    "    \n",
    "    for col in ['rating', 'n_votes', 'review_text']:\n",
    "        if col in combined_df_clean.columns:\n",
    "            combined_df_clean[col] = combined_df_clean[col].fillna(0)\n",
    "    \n",
    "    sentiment_results = combined_df_clean.apply(get_review_sentiment, axis=1)\n",
    "    sentiment_df = pd.DataFrame(sentiment_results.tolist())\n",
    "    \n",
    "    enhanced_df = pd.concat([combined_df_clean, sentiment_df], axis=1)\n",
    "    \n",
    "    if 'book_id' not in enhanced_df.columns:\n",
    "        print(\"Error: book_id column missing from dataframe\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    if len(enhanced_df['book_id'].unique()) == 0:\n",
    "        print(\"Error: No unique book_ids found\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    agg_dict = {}\n",
    "    \n",
    "    if 'title' in enhanced_df.columns:\n",
    "        agg_dict['title'] = 'first'\n",
    "    \n",
    "    for col in ['weighted_score', 'text_sentiment', 'rating_sentiment']:\n",
    "        if col in enhanced_df.columns:\n",
    "            agg_dict[col] = ['mean', 'count', 'std']\n",
    "    \n",
    "    if 'rating' in enhanced_df.columns:\n",
    "        agg_dict['rating'] = ['mean', 'count', 'std']\n",
    "    \n",
    "    if 'n_votes' in enhanced_df.columns:\n",
    "        agg_dict['n_votes'] = ['sum', 'mean']\n",
    "    \n",
    "    book_polarity = enhanced_df.groupby('book_id').agg(agg_dict)\n",
    "    \n",
    "    book_polarity.columns = ['_'.join(col).strip() for col in book_polarity.columns.values]\n",
    "    \n",
    "    def get_polarity_category(score):\n",
    "        if score >= 0.7:\n",
    "            return \"Extremely Positive\"\n",
    "        elif score >= 0.5:\n",
    "            return \"Very Positive\"\n",
    "        elif score >= 0.25:\n",
    "            return \"Positive\"\n",
    "        elif score >= -0.25:\n",
    "            return \"Neutral\"\n",
    "        elif score >= -0.5:\n",
    "            return \"Negative\"\n",
    "        else:\n",
    "            return \"Very Negative\"\n",
    "    \n",
    "    if 'weighted_score_mean' in book_polarity.columns:\n",
    "        book_polarity['polarity_category'] = book_polarity['weighted_score_mean'].apply(get_polarity_category)\n",
    "    else:\n",
    "        book_polarity['polarity_category'] = \"Unknown\"\n",
    "    \n",
    "    book_polarity = book_polarity.reset_index()\n",
    "    \n",
    "    book_polarity['controversy_score'] = 0\n",
    "    \n",
    "    if 'text_sentiment_std' in book_polarity.columns and 'rating_std' in book_polarity.columns:\n",
    "        book_polarity['controversy_score'] = book_polarity['text_sentiment_std'] * book_polarity['rating_std']\n",
    "    \n",
    "    if 'weighted_score_mean' in book_polarity.columns and 'weighted_score_count' in book_polarity.columns:\n",
    "        # Create a high score multiplier that gives priority to scores >= 0.7\n",
    "        book_polarity['high_score_bonus'] = book_polarity['weighted_score_mean'].apply(\n",
    "            lambda x: 2.0 if x >= 0.7 else 1.0\n",
    "        )\n",
    "        \n",
    "        # Popularity score with higher emphasis on review count for highly rated books\n",
    "        book_polarity['popularity_score'] = (\n",
    "            book_polarity['weighted_score_mean'] * \n",
    "            book_polarity['high_score_bonus'] * \n",
    "            (1 + np.log1p(book_polarity['weighted_score_count']) / 3)\n",
    "        )\n",
    "        \n",
    "        # First sort by high_score_bonus (to prioritize 0.7+ scores), then by popularity score\n",
    "        book_polarity = book_polarity.sort_values(\n",
    "            ['high_score_bonus', 'popularity_score'], \n",
    "            ascending=[False, False]\n",
    "        )\n",
    "    elif 'weighted_score_mean' in book_polarity.columns:\n",
    "        book_polarity = book_polarity.sort_values('weighted_score_mean', ascending=False)\n",
    "    \n",
    "    return book_polarity\n",
    "\n",
    "def display_book_polarity_summary(book_polarity_df):\n",
    "    if len(book_polarity_df) == 0:\n",
    "        print(\"No books to analyze\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\nBook Sentiment Analysis Summary:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(f\"\\nTotal books analyzed: {len(book_polarity_df)}\")\n",
    "    \n",
    "    if 'polarity_category' in book_polarity_df.columns:\n",
    "        category_counts = book_polarity_df['polarity_category'].value_counts()\n",
    "        print(\"\\nPolarity Category Distribution:\")\n",
    "        for category, count in category_counts.items():\n",
    "            print(f\"{category}: {count} books ({count/len(book_polarity_df)*100:.1f}%)\")\n",
    "    \n",
    "    # Display highly rated books (score >= 0.7) first\n",
    "    if 'weighted_score_mean' in book_polarity_df.columns:\n",
    "        high_scoring_books = book_polarity_df[book_polarity_df['weighted_score_mean'] >= 0.7]\n",
    "        if len(high_scoring_books) > 0:\n",
    "            print(\"\\nTop Books with Scores ≥ 0.7 (ordered by review count):\")\n",
    "            high_sorted = high_scoring_books.sort_values('weighted_score_count', ascending=False).head(\n",
    "                min(5, len(high_scoring_books))\n",
    "            )\n",
    "            for _, book in high_sorted.iterrows():\n",
    "                review_count = book.get('weighted_score_count', 'N/A')\n",
    "                print(f\"- {book['title_first']} (Score: {book['weighted_score_mean']:.2f}, Reviews: {review_count})\")\n",
    "    \n",
    "    if 'popularity_score' in book_polarity_df.columns and 'title_first' in book_polarity_df.columns:\n",
    "        print(\"\\nTop Books (combined score & popularity):\")\n",
    "        top_books = book_polarity_df.head(min(5, len(book_polarity_df)))\n",
    "        for _, book in top_books.iterrows():\n",
    "            review_count = book.get('weighted_score_count', 'N/A')\n",
    "            print(f\"- {book['title_first']} (Score: {book['weighted_score_mean']:.2f}, Reviews: {review_count}, Combined: {book['popularity_score']:.2f})\")\n",
    "    \n",
    "    if 'weighted_score_mean' in book_polarity_df.columns:\n",
    "        negative_books = book_polarity_df[book_polarity_df['weighted_score_mean'] < 0]\n",
    "        if len(negative_books) > 0:\n",
    "            print(\"\\nMost Negative Books:\")\n",
    "            top_negative = negative_books.head(min(5, len(negative_books)))\n",
    "            for _, book in top_negative.iterrows():\n",
    "                review_count = book.get('weighted_score_count', 'N/A')\n",
    "                print(f\"- {book['title_first']} (Score: {book['weighted_score_mean']:.2f}, Reviews: {review_count})\")\n",
    "        else:\n",
    "            print(\"\\nNo books with negative overall sentiment found.\")\n",
    "    \n",
    "    if 'controversy_score' in book_polarity_df.columns and 'title_first' in book_polarity_df.columns:\n",
    "        print(\"\\nMost Controversial Books (mixed opinions):\")\n",
    "        controversial = book_polarity_df.sort_values('controversy_score', ascending=False).head(min(5, len(book_polarity_df)))\n",
    "        for _, book in controversial.iterrows():\n",
    "            review_count = book.get('weighted_score_count', 'N/A')\n",
    "            print(f\"- {book['title_first']} (Controversy: {book['controversy_score']:.2f}, Reviews: {review_count})\")\n",
    "    \n",
    "    return\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        review_counts = book_review_df['book_id'].value_counts()\n",
    "        books_with_min_reviews = review_counts[review_counts >= 10].index\n",
    "        \n",
    "        if len(books_with_min_reviews) == 0:\n",
    "            print(\"No books found with at least 10 reviews\")\n",
    "            max_reviews = review_counts.max()\n",
    "            print(f\"Maximum reviews for any book: {max_reviews}\")\n",
    "            print(\"Using all data instead\")\n",
    "            filtered_df = book_review_df\n",
    "        else:\n",
    "            print(f\"Found {len(books_with_min_reviews)} books with at least 10 reviews\")\n",
    "            filtered_df = book_review_df[book_review_df['book_id'].isin(books_with_min_reviews)]\n",
    "        \n",
    "        book_polarity = analyze_review_polarity(filtered_df)\n",
    "        display_book_polarity_summary(book_polarity)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9523e6f-1576-4922-a172-5fcb96cb2ccb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b549bf7f-c89f-47da-8f0a-ea6686a181a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34cffaf4-7c41-449a-8b64-aed90b6f1630",
   "metadata": {},
   "source": [
    "### Inspecting Interaction DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854ffb99-6b66-4356-ae5b-eacd7088a980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded goodreads_interactions_children.json\n",
      "Successfully loaded goodreads_interactions_young_adult.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def load_interaction_data():\n",
    "    json_files = ['goodreads_interactions_children.json', 'goodreads_interactions_young_adult.json']\n",
    "    data = []\n",
    "\n",
    "    for json_file in json_files:\n",
    "        try:\n",
    "            with open(json_file, 'r') as file:\n",
    "                for line in file:\n",
    "                    record = json.loads(line)\n",
    "                    data.append(record)\n",
    "            print(f\"Successfully loaded {json_file}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {json_file}\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"JSON decode error in {json_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {json_file}: {str(e)}\")\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    interactions_df = pd.DataFrame(data)\n",
    "    \n",
    "    # Print basic info\n",
    "    print(f\"\\nLoaded {len(interactions_df)} interaction records\")\n",
    "    print(\"\\nColumns:\")\n",
    "    for col in interactions_df.columns:\n",
    "        print(f\"- {col}\")\n",
    "    \n",
    "    # Print sample data\n",
    "    print(\"\\nSample data (first 5 rows):\")\n",
    "    print(interactions_df.head())\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\nSummary statistics:\")\n",
    "    print(f\"Number of unique users: {interactions_df['user_id'].nunique()}\")\n",
    "    print(f\"Number of unique books: {interactions_df['book_id'].nunique()}\")\n",
    "    \n",
    "    # Check if common statistics columns exist before calculating\n",
    "    if 'rating' in interactions_df.columns:\n",
    "        print(f\"Average rating: {interactions_df['rating'].mean():.2f}\")\n",
    "    if 'is_read' in interactions_df.columns:\n",
    "        print(f\"Number of books read: {interactions_df['is_read'].sum()}\")\n",
    "    \n",
    "    return interactions_df\n",
    "\n",
    "# This can be called to load the interaction data\n",
    "if __name__ == \"__main__\":\n",
    "    interactions_df = load_interaction_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfed2c06-1d11-4195-9c92-75cea4038885",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af376eac-fc77-4f07-8b43-2e29f426dc16",
   "metadata": {},
   "source": [
    "## Detect Book Genre using book attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abbc641-6179-4f72-a7e3-22603ac9afdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import spacy\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def detect_book_genre_with_advanced_nlp(book_data, genre_classifier=None, min_confidence=3, exclude_shelves=None):\n",
    "    \"\"\"\n",
    "    Detect book genres using a combination of structured data analysis and advanced NLP techniques.\n",
    "    \n",
    "    Algorithm:\n",
    "    1. Extract genres from user-assigned shelves (most reliable signal)\n",
    "    2. Apply multiple NLP techniques to analyze book description and title:\n",
    "       - Semantic similarity using sentence embeddings\n",
    "       - TF-IDF analysis with genre-specific vocabulary\n",
    "       - Named entity recognition to identify genre-related entities\n",
    "    3. Extract additional signals from book metadata (page count, title patterns)\n",
    "    4. Combine all signals with appropriate weights (shelf data > NLP > metadata)\n",
    "    5. Return top genres that meet minimum confidence threshold\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    book_data : dict or pandas Series\n",
    "        Book information containing title, description, popular_shelves and other metadata\n",
    "    genre_classifier : object, optional\n",
    "        Optional pre-trained genre classifier model\n",
    "    min_confidence : int, optional\n",
    "        Minimum confidence score required to include a genre in the results\n",
    "    exclude_shelves : set, optional\n",
    "        Set of shelf names to exclude from analysis (e.g., 'to-read')\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    list\n",
    "        List of up to 3 most likely genres for the book\n",
    "    \"\"\"\n",
    "    if exclude_shelves is None:\n",
    "        exclude_shelves = get_default_excluded_shelves()\n",
    "    \n",
    "    # Extract genres from structured shelf data\n",
    "    shelf_genres = extract_genres_from_shelves(book_data, get_genre_map(), exclude_shelves)\n",
    "    \n",
    "    title = str(book_data.get('title', ''))\n",
    "    description = str(book_data.get('description', ''))\n",
    "    \n",
    "    nlp_genres = {}\n",
    "    \n",
    "    # Only perform NLP analysis if we have enough text\n",
    "    if len(description) > 20:\n",
    "        nlp_genres.update(analyze_with_embeddings(title, description))\n",
    "        nlp_genres.update(analyze_with_tfidf(title, description))\n",
    "        nlp_genres.update(extract_named_entities(title, description))\n",
    "    \n",
    "    # Extract genre signals from book metadata\n",
    "    metadata_genres = analyze_metadata(book_data)\n",
    "    \n",
    "    # Combine all signals and apply minimum confidence threshold\n",
    "    final_genres = combine_all_genre_signals(shelf_genres, nlp_genres, metadata_genres, min_confidence)\n",
    "    \n",
    "    return final_genres[:3]\n",
    "\n",
    "\n",
    "def get_default_excluded_shelves():\n",
    "    \"\"\"\n",
    "    Get the default set of shelf names to exclude from genre analysis.\n",
    "    \n",
    "    Algorithm:\n",
    "    - Return a predefined set of non-genre shelves that are commonly used but don't indicate genre\n",
    "      (e.g., organizational shelves like \"to-read\" or format shelves like \"ebook\")\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    set\n",
    "        Set of shelf names that aren't useful for genre classification\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'to-read', 'currently-reading', 'owned', 'default', \n",
    "        'favorites', 'books-i-own', 'ebook', 'kindle', \n",
    "        'library', 'audiobook', 'owned-books', 'to-buy', \n",
    "        'calibre', 're-read', 'unread', 'favourites', 'my-books'\n",
    "    }\n",
    "\n",
    "\n",
    "def get_genre_map():\n",
    "    \"\"\"\n",
    "    Get mapping from common shelf keywords to standardized genre names.\n",
    "    \n",
    "    Algorithm:\n",
    "    - Create a dictionary that maps various ways users might tag a genre (e.g., \"sci-fi\", \"science-fiction\") \n",
    "      to a standardized genre name (\"Science Fiction\")\n",
    "    - This normalizes different variations of the same genre concept\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary mapping shelf keywords to standardized genre names\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'fantasy': 'Fantasy',\n",
    "        'sci-fi': 'Science Fiction',\n",
    "        'science-fiction': 'Science Fiction',\n",
    "        'mystery': 'Mystery/Thriller',\n",
    "        'thriller': 'Mystery/Thriller',\n",
    "        'romance': 'Romance',\n",
    "        'historical': 'Historical Fiction',\n",
    "        'history': 'History',\n",
    "        'horror': 'Horror',\n",
    "        'young-adult': 'Young Adult',\n",
    "        'ya': 'Young Adult',\n",
    "        'childrens': 'Children\\'s',\n",
    "        'children': 'Children\\'s',\n",
    "        'kids': 'Children\\'s',\n",
    "        'dystopian': 'Dystopian',\n",
    "        'classic': 'Classics',\n",
    "        'classics': 'Classics',\n",
    "        'biography': 'Biography/Memoir',\n",
    "        'memoir': 'Biography/Memoir',\n",
    "        'autobiography': 'Biography/Memoir',\n",
    "        'self-help': 'Self Help',\n",
    "        'business': 'Business',\n",
    "        'philosophy': 'Philosophy',\n",
    "        'psychology': 'Psychology',\n",
    "        'science': 'Science',\n",
    "        'poetry': 'Poetry',\n",
    "        'comic': 'Comics/Graphic Novels',\n",
    "        'graphic-novel': 'Comics/Graphic Novels',\n",
    "        'manga': 'Manga',\n",
    "        'cooking': 'Cooking/Food',\n",
    "        'cookbook': 'Cooking/Food',\n",
    "        'food': 'Cooking/Food',\n",
    "        'travel': 'Travel',\n",
    "        'religion': 'Religion/Spirituality',\n",
    "        'spirituality': 'Religion/Spirituality',\n",
    "        'art': 'Art/Photography',\n",
    "        'photography': 'Art/Photography',\n",
    "        'reference': 'Reference',\n",
    "        'textbook': 'Textbook/Education',\n",
    "        'education': 'Textbook/Education'\n",
    "    }\n",
    "\n",
    "\n",
    "def get_genre_embeddings():\n",
    "    \"\"\"\n",
    "    Get descriptions of genres for semantic similarity comparisons.\n",
    "    \n",
    "    Algorithm:\n",
    "    - Define rich textual descriptions for each genre containing key concepts and vocabulary\n",
    "    - These descriptions will be used to create embeddings for semantic similarity comparison\n",
    "      with the book's content\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary mapping genre names to their textual descriptions\n",
    "    \"\"\"\n",
    "    genre_descriptions = {\n",
    "        'Fantasy': 'Magic, wizards, dragons, mythical creatures, quests, magical worlds and kingdoms',\n",
    "        'Science Fiction': 'Space, technology, future, aliens, robots, artificial intelligence, dystopian societies',\n",
    "        'Mystery/Thriller': 'Crime, murder, detective, investigation, suspense, secrets, conspiracy',\n",
    "        'Romance': 'Love, relationships, passion, emotion, marriage, dating, feelings',\n",
    "        'Historical Fiction': 'Past events, historical periods, ancient civilizations, history-based stories',\n",
    "        'Horror': 'Fear, terror, supernatural, monsters, ghosts, nightmares, scary stories',\n",
    "        'Young Adult': 'Teenage protagonists, coming of age, high school, identity, friendship, young romance',\n",
    "        'Children\\'s': 'Stories for kids, picture books, educational, simple stories, colorful illustrations',\n",
    "        'Biography/Memoir': 'Real life stories, personal experiences, autobiographical, true events',\n",
    "        'Self Help': 'Personal improvement, advice, motivation, success strategies, life guidance',\n",
    "        'Business': 'Entrepreneurship, finance, management, marketing, career advice, economics',\n",
    "        'History': 'Historical accounts, wars, civilizations, historical figures, factual accounts of the past',\n",
    "        'Science': 'Scientific discoveries, research, theories, nature, biology, physics, academic',\n",
    "        'Poetry': 'Poems, verse, rhymes, poetic language, collections of poetry',\n",
    "        'Dystopian': 'Oppressive society, controlled world, rebellion, survival, future dystopia',\n",
    "        'Classics': 'Literary works of lasting value, canonical literature, traditional important works',\n",
    "        'Religion/Spirituality': 'Faith, belief systems, religious practices, spiritual growth, theology',\n",
    "        'Comics/Graphic Novels': 'Illustrated stories, sequential art, comic book format, visual storytelling',\n",
    "        'Cooking/Food': 'Recipes, culinary techniques, food culture, cooking instructions, nutrition',\n",
    "        'Travel': 'Travel guides, destinations, journeys, cultural exploration, adventures abroad'\n",
    "    }\n",
    "    return genre_descriptions\n",
    "\n",
    "\n",
    "def extract_genres_from_shelves(book_data, genre_map, exclude_shelves):\n",
    "    \"\"\"\n",
    "    Extract genre information from book's popular shelves data.\n",
    "    \n",
    "    Algorithm:\n",
    "    1. Iterate through the book's popular shelves data\n",
    "    2. Filter out non-genre shelves (using exclude_shelves)\n",
    "    3. Map shelf names to standardized genres using genre_map\n",
    "    4. Use shelf counts as confidence scores (more users shelving = higher confidence)\n",
    "    5. Return accumulated genre scores from shelf data\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    book_data : dict or pandas Series\n",
    "        Book information containing popular_shelves\n",
    "    genre_map : dict\n",
    "        Dictionary mapping shelf keywords to standardized genre names\n",
    "    exclude_shelves : set\n",
    "        Set of shelf names to exclude from analysis\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary of genre names with their confidence scores from shelf data\n",
    "    \"\"\"\n",
    "    shelf_genres = {}\n",
    "    \n",
    "    popular_shelves = book_data.get('popular_shelves', [])\n",
    "    if isinstance(popular_shelves, list) and popular_shelves:\n",
    "        for shelf in popular_shelves:\n",
    "            shelf_name = shelf.get('name', '').strip().lower()\n",
    "            shelf_count = int(shelf.get('count', 0))\n",
    "            \n",
    "            if shelf_name in exclude_shelves:\n",
    "                continue\n",
    "            \n",
    "            for keyword, genre_name in genre_map.items():\n",
    "                if keyword in shelf_name:\n",
    "                    if genre_name in shelf_genres:\n",
    "                        shelf_genres[genre_name] += shelf_count\n",
    "                    else:\n",
    "                        shelf_genres[genre_name] = shelf_count\n",
    "                    break\n",
    "    \n",
    "    return shelf_genres\n",
    "\n",
    "\n",
    "def preprocess_text(text, lemmatize=True):\n",
    "    \"\"\"\n",
    "    Preprocess text by removing special characters, lemmatizing, etc.\n",
    "    \n",
    "    Algorithm:\n",
    "    1. Convert text to lowercase\n",
    "    2. Remove URLs and HTML tags\n",
    "    3. Remove non-alphabetic characters\n",
    "    4. Normalize whitespace\n",
    "    5. Optionally lemmatize words (reduce to base form)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Text to preprocess\n",
    "    lemmatize : bool, optional\n",
    "        Whether to apply lemmatization (default: True)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    str\n",
    "        Preprocessed text\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    if lemmatize:\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        word_list = nltk.word_tokenize(text)\n",
    "        text = ' '.join([lemmatizer.lemmatize(word) for word in word_list])\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def load_nlp_models():\n",
    "    \"\"\"\n",
    "    Load NLP models required for text analysis.\n",
    "    \n",
    "    Algorithm:\n",
    "    1. Try to load spaCy model for named entity recognition\n",
    "    2. Try to load sentence transformer model for text embeddings\n",
    "    3. Handle any exceptions if models aren't available or can't be downloaded\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (spacy_model, embedding_model) - loaded NLP models\n",
    "    \"\"\"\n",
    "    try:\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "    except:\n",
    "        try:\n",
    "            spacy.cli.download(\"en_core_web_sm\")\n",
    "            nlp = spacy.load(\"en_core_web_sm\")\n",
    "        except:\n",
    "            nlp = None\n",
    "            \n",
    "    try:\n",
    "        embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    except:\n",
    "        embedding_model = None\n",
    "    \n",
    "    return nlp, embedding_model\n",
    "\n",
    "\n",
    "def analyze_with_embeddings(title, description):\n",
    "    \"\"\"\n",
    "    Analyze book text using sentence embeddings for semantic similarity.\n",
    "    \n",
    "    Algorithm:\n",
    "    1. Load pretrained sentence transformer model\n",
    "    2. Create embeddings for genre descriptions\n",
    "    3. Create embedding for the book (title + description)\n",
    "    4. Calculate cosine similarity between book embedding and genre embeddings\n",
    "    5. Convert similarities to confidence scores and return top matches\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    title : str\n",
    "        Book title\n",
    "    description : str\n",
    "        Book description\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary of genre names with their confidence scores from embedding analysis\n",
    "    \"\"\"\n",
    "    try:\n",
    "        model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        \n",
    "        genre_descriptions = get_genre_embeddings()\n",
    "        genre_texts = [f\"{genre}: {desc}\" for genre, desc in genre_descriptions.items()]\n",
    "        genre_embeddings = model.encode(genre_texts)\n",
    "        \n",
    "        book_text = f\"{title} {description}\"\n",
    "        book_embedding = model.encode([book_text])[0]\n",
    "        \n",
    "        similarities = cosine_similarity([book_embedding], genre_embeddings)[0]\n",
    "        \n",
    "        genres = {}\n",
    "        for i, genre in enumerate(genre_descriptions.keys()):\n",
    "            score = int(similarities[i] * 10)\n",
    "            if score > 3:\n",
    "                genres[genre] = score\n",
    "                \n",
    "        return genres\n",
    "    except:\n",
    "        return {}\n",
    "\n",
    "\n",
    "def analyze_with_tfidf(title, description):\n",
    "    \"\"\"\n",
    "    Analyze book text using TF-IDF comparison against genre-specific vocabulary.\n",
    "    \n",
    "    Algorithm:\n",
    "    1. Define genre-specific keyword sets\n",
    "    2. Preprocess the book text (title + description)\n",
    "    3. Create TF-IDF vectors for genre keywords and book text\n",
    "    4. Calculate cosine similarity between book vector and each genre vector\n",
    "    5. Convert similarities to confidence scores and return top matches\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    title : str\n",
    "        Book title\n",
    "    description : str\n",
    "        Book description\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary of genre names with their confidence scores from TF-IDF analysis\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Define genre keyword sets\n",
    "        genre_keywords = {\n",
    "            'Fantasy': 'magic wizard dragon elf quest sword magical kingdom witch sorcery myth fantasy',\n",
    "            'Science Fiction': 'space alien future technology robot dystopian sci-fi futuristic planet spacecraft',\n",
    "            'Mystery/Thriller': 'murder detective crime case investigation killer suspense clue mystery conspiracy',\n",
    "            'Romance': 'love relationship passion romantic heart affair marriage emotion desire dating romance',\n",
    "            'Historical Fiction': 'century historical period king queen ancient war empire era medieval history',\n",
    "            'Horror': 'fear terror ghost scary monster supernatural haunt nightmare blood evil dark horror',\n",
    "            'Young Adult': 'teen school young coming-of-age adolescent teenage youth friendship high-school',\n",
    "            'Children\\'s': 'child kid young picture-book learning bedtime simple adventure colorful illustrated',\n",
    "            'Biography/Memoir': 'life autobiography personal real journey memoir experience story true figure',\n",
    "            'Self Help': 'improve success happiness guide advice life motivation habit inspiration growth',\n",
    "            'Business': 'market company entrepreneur success management leadership strategy finance career investment',\n",
    "            'Dystopian': 'dystopia future society control survival oppression rebellion totalitarian apocalyptic regime'\n",
    "        }\n",
    "        \n",
    "        # Preprocess text\n",
    "        processed_text = preprocess_text(f\"{title} {description}\")\n",
    "        \n",
    "        # Create TF-IDF vectorizer\n",
    "        vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "        \n",
    "        # Create corpus with genre keywords and the book text\n",
    "        corpus = list(genre_keywords.values())\n",
    "        corpus.append(processed_text)\n",
    "        \n",
    "        # Calculate TF-IDF\n",
    "        tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "        \n",
    "        # Calculate similarity between book and each genre\n",
    "        last_row_index = tfidf_matrix.shape[0] - 1\n",
    "        similarities = cosine_similarity(tfidf_matrix[last_row_index], tfidf_matrix[:-1])[0]\n",
    "        \n",
    "        # Map similarities to genres\n",
    "        genres = {}\n",
    "        for i, genre in enumerate(genre_keywords.keys()):\n",
    "            # Convert similarity scores to a more intuitive range (0-10)\n",
    "            score = int(similarities[i] * 10)\n",
    "            if score > 3:  # Only consider reasonable matches\n",
    "                genres[genre] = score\n",
    "                \n",
    "        return genres\n",
    "    except:\n",
    "        return {}\n",
    "\n",
    "\n",
    "def extract_named_entities(title, description):\n",
    "    \"\"\"\n",
    "    Extract named entities from book text and map them to potential genres.\n",
    "    \n",
    "    Algorithm:\n",
    "    1. Load spaCy NLP model\n",
    "    2. Process the text to extract named entities\n",
    "    3. Match entities against genre-related keyword lists\n",
    "    4. Score genres based on matched entities\n",
    "    5. Return genres with their confidence scores\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    title : str\n",
    "        Book title\n",
    "    description : str\n",
    "        Book description\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary of genre names with their confidence scores from entity analysis\n",
    "    \"\"\"\n",
    "    try:\n",
    "        nlp, _ = load_nlp_models()\n",
    "        if not nlp:\n",
    "            return {}\n",
    "            \n",
    "        # Process text with spaCy\n",
    "        doc = nlp(f\"{title} {description}\")\n",
    "        \n",
    "        # Extract entities\n",
    "        entities = [ent.text.lower() for ent in doc.ents]\n",
    "        \n",
    "        # Define entity-genre associations\n",
    "        entity_genre_map = {\n",
    "            'fantasy': ['magic', 'wizard', 'dragon', 'elf', 'fairy', 'kingdom', 'quest', 'sorcerer'],\n",
    "            'science fiction': ['space', 'planet', 'alien', 'robot', 'future', 'technology'],\n",
    "            'historical fiction': ['century', 'king', 'queen', 'empire', 'war', 'battle', 'medieval', 'ancient'],\n",
    "            'biography': ['life', 'biography', 'autobiography', 'memoir', 'president', 'politician', 'artist'],\n",
    "            'science': ['research', 'experiment', 'theory', 'physics', 'biology', 'chemistry', 'scientist'],\n",
    "            'religion': ['god', 'church', 'bible', 'faith', 'spiritual', 'religion', 'prayer']\n",
    "        }\n",
    "        \n",
    "        # Find genres based on entities\n",
    "        genres = {}\n",
    "        for entity in entities:\n",
    "            for genre, keywords in entity_genre_map.items():\n",
    "                if any(keyword in entity for keyword in keywords):\n",
    "                    standardized_genre = standardize_genre(genre)\n",
    "                    genres[standardized_genre] = genres.get(standardized_genre, 0) + 1\n",
    "                    \n",
    "        return genres\n",
    "    except:\n",
    "        return {}\n",
    "\n",
    "\n",
    "def standardize_genre(genre):\n",
    "    \"\"\"\n",
    "    Standardize genre names to a consistent format.\n",
    "    \n",
    "    Algorithm:\n",
    "    - Map various genre name formats to standardized genre names\n",
    "    - Default to title case if no mapping exists\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    genre : str\n",
    "        Genre name to standardize\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    str\n",
    "        Standardized genre name\n",
    "    \"\"\"\n",
    "    genre_map = {\n",
    "        'fantasy': 'Fantasy',\n",
    "        'science fiction': 'Science Fiction',\n",
    "        'historical fiction': 'Historical Fiction',\n",
    "        'biography': 'Biography/Memoir',\n",
    "        'science': 'Science',\n",
    "        'religion': 'Religion/Spirituality'\n",
    "    }\n",
    "    return genre_map.get(genre.lower(), genre.title())\n",
    "\n",
    "\n",
    "def analyze_metadata(book_data):\n",
    "    \"\"\"\n",
    "    Analyze book metadata for additional genre signals.\n",
    "    \n",
    "    Algorithm:\n",
    "    1. Check page count (short books may be children's books)\n",
    "    2. Look for series indicators in title (common in fantasy, sci-fi, YA)\n",
    "    3. Look for children's book indicators in title\n",
    "    4. Look for educational/textbook indicators in title\n",
    "    5. Return genre scores derived from metadata\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    book_data : dict or pandas Series\n",
    "        Book information containing metadata\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary of genre names with their confidence scores from metadata\n",
    "    \"\"\"\n",
    "    metadata_genres = {}\n",
    "    \n",
    "    # Check page count for children's books\n",
    "    if 'num_pages' in book_data and book_data['num_pages'] and pd.notna(book_data['num_pages']):\n",
    "        try:\n",
    "            pages = int(book_data['num_pages'])\n",
    "            if pages < 50:\n",
    "                metadata_genres[\"Children's\"] = 5\n",
    "        except (ValueError, TypeError):\n",
    "            pass\n",
    "    \n",
    "    # Check title for series indicators\n",
    "    title = str(book_data.get('title', '')).lower()\n",
    "    series_indicators = ['#1', '#2', '#3', 'book 1', 'book 2', 'trilogy', 'series', 'volume']\n",
    "    \n",
    "    if any(indicator in title for indicator in series_indicators):\n",
    "        metadata_genres['Fantasy'] = metadata_genres.get('Fantasy', 0) + 2\n",
    "        metadata_genres['Science Fiction'] = metadata_genres.get('Science Fiction', 0) + 2\n",
    "        metadata_genres['Young Adult'] = metadata_genres.get('Young Adult', 0) + 2\n",
    "    \n",
    "    # Check for children's book indicators in title\n",
    "    children_indicators = ['for kids', 'for children', 'children\\'s', 'picture book', 'baby', 'toddler']\n",
    "    if any(indicator in title for indicator in children_indicators):\n",
    "        metadata_genres[\"Children's\"] = metadata_genres.get(\"Children's\", 0) + 5\n",
    "    \n",
    "    # Check for educational/textbook indicators\n",
    "    educational_indicators = ['textbook', 'introduction to', 'principles of', 'fundamentals of', 'guide to']\n",
    "    if any(indicator in title for indicator in educational_indicators):\n",
    "        metadata_genres['Textbook/Education'] = 5\n",
    "    \n",
    "    return metadata_genres\n",
    "\n",
    "\n",
    "def combine_all_genre_signals(shelf_genres, nlp_genres, metadata_genres, min_confidence):\n",
    "    \"\"\"\n",
    "    Combine genre signals from different sources with appropriate weights.\n",
    "    \n",
    "    Algorithm:\n",
    "    1. Start with shelf genres (highest weight x3)\n",
    "    2. Add NLP-detected genres (medium weight x2)\n",
    "    3. Add metadata-based genres (normal weight x1)\n",
    "    4. Sort by final weighted score\n",
    "    5. Filter by minimum confidence threshold\n",
    "    6. Return top genres, or fallback to highest scoring genre if none meet threshold\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    shelf_genres : dict\n",
    "        Genres detected from shelves data\n",
    "    nlp_genres : dict\n",
    "        Genres detected from NLP analysis\n",
    "    metadata_genres : dict\n",
    "        Genres detected from metadata\n",
    "    min_confidence : int\n",
    "        Minimum confidence score to include a genre\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    list\n",
    "        Final list of detected genres in order of confidence\n",
    "    \"\"\"\n",
    "    combined_scores = Counter()\n",
    "    \n",
    "    # Add shelf genres with highest weight (explicit human categorization)\n",
    "    for genre, score in shelf_genres.items():\n",
    "        combined_scores[genre] += score * 3\n",
    "    \n",
    "    # Add NLP-detected genres with medium weight\n",
    "    for genre, score in nlp_genres.items():\n",
    "        combined_scores[genre] += score * 2\n",
    "    \n",
    "    # Add metadata-based genres\n",
    "    for genre, score in metadata_genres.items():\n",
    "        combined_scores[genre] += score\n",
    "    \n",
    "    # Sort by final score\n",
    "    sorted_genres = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Filter by minimum confidence\n",
    "    final_genres = [genre for genre, score in sorted_genres if score >= min_confidence]\n",
    "    \n",
    "    # Fallback if no confident genres\n",
    "    if not final_genres and sorted_genres:\n",
    "        final_genres = [sorted_genres[0][0]]\n",
    "    \n",
    "    return final_genres\n",
    "\n",
    "\n",
    "def test_genre_detection():\n",
    "    \"\"\"\n",
    "    Test genre detection on 5 popular book examples.\n",
    "    \n",
    "    Algorithm:\n",
    "    1. Download required NLTK resources\n",
    "    2. Create test dataset of 5 popular books with metadata\n",
    "    3. Apply genre detection algorithm to each book\n",
    "    4. Print results for each book\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame containing the test books\n",
    "    \"\"\"\n",
    "    try:\n",
    "        nltk.download('punkt', quiet=True)\n",
    "        nltk.download('stopwords', quiet=True)\n",
    "        nltk.download('wordnet', quiet=True)\n",
    "    except:\n",
    "        print(\"NLTK download failed, but continuing...\")\n",
    "        \n",
    "    test_books = [\n",
    "        {\n",
    "            'book_id': 1,\n",
    "            'title': 'Harry Potter and the Sorcerer\\'s Stone',\n",
    "            'average_rating': 4.47,\n",
    "            'ratings_count': 6800000,\n",
    "            'description': 'Harry Potter has never been the star of a Quidditch team, scoring points while riding a broom far above the ground. He knows no spells, has never helped to hatch a dragon, and has never worn a cloak of invisibility. All he knows is a miserable life with the Dursleys, his horrible aunt and uncle, and their abominable son, Dudley — a great big swollen spoiled bully. Harry\\'s room is a tiny closet at the foot of the stairs, and he hasn\\'t had a birthday party in eleven years. But all that is about to change when a mysterious letter arrives by owl messenger: a letter with an invitation to an incredible place that Harry — and anyone who reads about him — will find unforgettable.',\n",
    "            'num_pages': 309,\n",
    "            'similar_books': [],\n",
    "            'popular_shelves': [\n",
    "                {'count': '15000', 'name': 'to-read'},\n",
    "                {'count': '12000', 'name': 'fantasy'},\n",
    "                {'count': '8000', 'name': 'young-adult'},\n",
    "                {'count': '4000', 'name': 'fiction'},\n",
    "                {'count': '3000', 'name': 'favorites'}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'book_id': 2,\n",
    "            'title': 'The Da Vinci Code',\n",
    "            'average_rating': 3.89,\n",
    "            'ratings_count': 1900000,\n",
    "            'description': 'While in Paris, Harvard symbologist Robert Langdon is awakened by a phone call in the dead of the night. The elderly curator of the Louvre has been murdered inside the museum, his body covered in baffling symbols. As Langdon and gifted French cryptologist Sophie Neveu sort through the bizarre riddles, they are stunned to discover a trail of clues hidden in the works of Leonardo da Vinci—clues visible for all to see and yet ingeniously disguised by the painter.',\n",
    "            'num_pages': 489,\n",
    "            'similar_books': [],\n",
    "            'popular_shelves': [\n",
    "                {'count': '10000', 'name': 'to-read'},\n",
    "                {'count': '8000', 'name': 'thriller'},\n",
    "                {'count': '7000', 'name': 'mystery'},\n",
    "                {'count': '5000', 'name': 'fiction'},\n",
    "                {'count': '2000', 'name': 'suspense'}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'book_id': 3,\n",
    "            'title': 'To Kill a Mockingbird',\n",
    "            'average_rating': 4.28,\n",
    "            'ratings_count': 4300000,\n",
    "            'description': 'The unforgettable novel of a childhood in a sleepy Southern town and the crisis of conscience that rocked it. \"To Kill A Mockingbird\" became both an instant bestseller and a critical success when it was first published in 1960. It went on to win the Pulitzer Prize in 1961 and was later made into an Academy Award-winning film, also a classic.',\n",
    "            'num_pages': 324,\n",
    "            'similar_books': [],\n",
    "            'popular_shelves': [\n",
    "                {'count': '11000', 'name': 'to-read'},\n",
    "                {'count': '9000', 'name': 'classics'},\n",
    "                {'count': '7000', 'name': 'fiction'},\n",
    "                {'count': '4000', 'name': 'school'},\n",
    "                {'count': '3000', 'name': 'literature'}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'book_id': 4,\n",
    "            'title': 'The Hunger Games',\n",
    "            'average_rating': 4.32,\n",
    "            'ratings_count': 6100000,\n",
    "            'description': 'In the ruins of a place once known as North America lies the nation of Panem, a shining Capitol surrounded by twelve outlying districts. The Capitol is harsh and cruel and keeps the districts in line by forcing them all to send one boy and one girl between the ages of twelve and eighteen to participate in the annual Hunger Games, a fight to the death on live TV.',\n",
    "            'num_pages': 374,\n",
    "            'similar_books': [],\n",
    "            'popular_shelves': [\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'book_id': 5,\n",
    "            'title': 'The Very Hungry Caterpillar',\n",
    "            'average_rating': 4.3,\n",
    "            'ratings_count': 527000,\n",
    "            'description': 'Eric Carle\\'s classic, The Very Hungry Caterpillar, with a simple counting concept, has been delighting young readers for more than 30 years. This board book edition is now available in a larger format, making it perfect for laptime reading.',\n",
    "            'num_pages': 26,\n",
    "            'similar_books': [],\n",
    "            'popular_shelves': [\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    df = pd.DataFrame(test_books)\n",
    "    \n",
    "    print(\"Testing genre detection on 5 popular books...\\n\")\n",
    "    \n",
    "    for i, book in enumerate(test_books):\n",
    "        print(f\"Book {i+1}: {book['title']}\")\n",
    "        \n",
    "        genres = detect_book_genre_with_advanced_nlp(book)\n",
    "        \n",
    "        print(f\"Detected genres: {', '.join(genres)}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_genre_detection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953aa8ef-953c-4ea8-8e86-fc2c8f92f726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ce1dfb-ee97-4d91-960d-80c6fd982544",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb39210c-133b-49fc-a3f1-12da910a1f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import spacy\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def detect_book_genre_with_advanced_nlp(book_data, genre_classifier=None, min_confidence=3, exclude_shelves=None):\n",
    "    \"\"\"\n",
    "    Detect book genres using a combination of structured data analysis and advanced NLP techniques.\n",
    "    Handles cases where shelf data or similar books may be missing.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    book_data : dict or pandas Series\n",
    "        Book information containing title, description, and other metadata\n",
    "    genre_classifier : object, optional\n",
    "        Optional pre-trained genre classifier model\n",
    "    min_confidence : int, optional\n",
    "        Minimum confidence score required to include a genre in the results\n",
    "    exclude_shelves : set, optional\n",
    "        Set of shelf names to exclude from analysis (e.g., 'to-read')\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    list\n",
    "        List of up to 3 most likely genres for the book\n",
    "    \"\"\"\n",
    "    if exclude_shelves is None:\n",
    "        exclude_shelves = get_default_excluded_shelves()\n",
    "    \n",
    "    title = str(book_data.get('title', ''))\n",
    "    description = str(book_data.get('description', ''))\n",
    "    \n",
    "    has_shelf_data = bool(book_data.get('popular_shelves', []))\n",
    "    \n",
    "    adjusted_min_confidence = min_confidence\n",
    "    if not has_shelf_data:\n",
    "        adjusted_min_confidence = max(1, min_confidence - 2)\n",
    "    \n",
    "    shelf_genres = extract_genres_from_shelves(book_data, get_genre_map(), exclude_shelves)\n",
    "    \n",
    "    nlp_genres = {}\n",
    "    if len(description) > 20:\n",
    "        nlp_genres.update(analyze_with_embeddings(title, description, boost=not has_shelf_data))\n",
    "        nlp_genres.update(analyze_with_tfidf(title, description, boost=not has_shelf_data))\n",
    "        nlp_genres.update(extract_named_entities(title, description))\n",
    "        nlp_genres.update(detect_specific_genre_patterns(title, description))\n",
    "    \n",
    "    metadata_genres = analyze_metadata(book_data)\n",
    "    \n",
    "    similar_book_genres = analyze_similar_books(book_data)\n",
    "    \n",
    "    final_genres = combine_all_genre_signals(shelf_genres, nlp_genres, metadata_genres, similar_book_genres, adjusted_min_confidence)\n",
    "    \n",
    "    if not final_genres:\n",
    "        final_genres = genre_fallback_detection(title, description)\n",
    "    \n",
    "    return final_genres[:3]\n",
    "\n",
    "\n",
    "def get_default_excluded_shelves():\n",
    "    \"\"\"\n",
    "    Get the default set of shelf names to exclude from genre analysis.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    set\n",
    "        Set of shelf names that aren't useful for genre classification\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'to-read', 'currently-reading', 'owned', 'default', \n",
    "        'favorites', 'books-i-own', 'ebook', 'kindle', \n",
    "        'library', 'audiobook', 'owned-books', 'to-buy', \n",
    "        'calibre', 're-read', 'unread', 'favourites', 'my-books'\n",
    "    }\n",
    "\n",
    "\n",
    "def get_genre_map():\n",
    "    \"\"\"\n",
    "    Get mapping from common shelf keywords to standardized genre names.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary mapping shelf keywords to standardized genre names\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'fantasy': 'Fantasy',\n",
    "        'sci-fi': 'Science Fiction',\n",
    "        'science-fiction': 'Science Fiction',\n",
    "        'mystery': 'Mystery/Thriller',\n",
    "        'thriller': 'Mystery/Thriller',\n",
    "        'romance': 'Romance',\n",
    "        'historical': 'Historical Fiction',\n",
    "        'history': 'History',\n",
    "        'horror': 'Horror',\n",
    "        'young-adult': 'Young Adult',\n",
    "        'ya': 'Young Adult',\n",
    "        'childrens': 'Children\\'s',\n",
    "        'children': 'Children\\'s',\n",
    "        'kids': 'Children\\'s',\n",
    "        'dystopian': 'Dystopian',\n",
    "        'classic': 'Classics',\n",
    "        'classics': 'Classics',\n",
    "        'biography': 'Biography/Memoir',\n",
    "        'memoir': 'Biography/Memoir',\n",
    "        'autobiography': 'Biography/Memoir',\n",
    "        'self-help': 'Self Help',\n",
    "        'business': 'Business',\n",
    "        'philosophy': 'Philosophy',\n",
    "        'psychology': 'Psychology',\n",
    "        'science': 'Science',\n",
    "        'poetry': 'Poetry',\n",
    "        'comic': 'Comics/Graphic Novels',\n",
    "        'graphic-novel': 'Comics/Graphic Novels',\n",
    "        'manga': 'Manga',\n",
    "        'cooking': 'Cooking/Food',\n",
    "        'cookbook': 'Cooking/Food',\n",
    "        'food': 'Cooking/Food',\n",
    "        'travel': 'Travel',\n",
    "        'religion': 'Religion/Spirituality',\n",
    "        'spirituality': 'Religion/Spirituality',\n",
    "        'art': 'Art/Photography',\n",
    "        'photography': 'Art/Photography',\n",
    "        'reference': 'Reference',\n",
    "        'textbook': 'Textbook/Education',\n",
    "        'education': 'Textbook/Education',\n",
    "        'academic': 'Textbook/Education',\n",
    "        'computer-science': 'Computer Science',\n",
    "        'programming': 'Computer Science',\n",
    "        'mathematics': 'Mathematics',\n",
    "        'statistics': 'Mathematics'\n",
    "    }\n",
    "\n",
    "\n",
    "def get_genre_embeddings():\n",
    "    \"\"\"\n",
    "    Get descriptions of genres for semantic similarity comparisons.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary mapping genre names to their textual descriptions\n",
    "    \"\"\"\n",
    "    genre_descriptions = {\n",
    "        'Fantasy': 'Magic, wizards, dragons, mythical creatures, quests, magical worlds and kingdoms',\n",
    "        'Science Fiction': 'Space, technology, future, aliens, robots, artificial intelligence, dystopian societies',\n",
    "        'Mystery/Thriller': 'Crime, murder, detective, investigation, suspense, secrets, conspiracy',\n",
    "        'Romance': 'Love, relationships, passion, emotion, marriage, dating, feelings',\n",
    "        'Historical Fiction': 'Past events, historical periods, ancient civilizations, history-based stories',\n",
    "        'Horror': 'Fear, terror, supernatural, monsters, ghosts, nightmares, scary stories',\n",
    "        'Young Adult': 'Teenage protagonists, coming of age, high school, identity, friendship, young romance',\n",
    "        'Children\\'s': 'Stories for kids, picture books, educational, simple stories, colorful illustrations',\n",
    "        'Biography/Memoir': 'Real life stories, personal experiences, autobiographical, true events',\n",
    "        'Self Help': 'Personal improvement, advice, motivation, success strategies, life guidance',\n",
    "        'Business': 'Entrepreneurship, finance, management, marketing, career advice, economics',\n",
    "        'History': 'Historical accounts, wars, civilizations, historical figures, factual accounts of the past',\n",
    "        'Science': 'Scientific discoveries, research, theories, nature, biology, physics, academic',\n",
    "        'Poetry': 'Poems, verse, rhymes, poetic language, collections of poetry',\n",
    "        'Dystopian': 'Oppressive society, controlled world, rebellion, survival, future dystopia, totalitarian government',\n",
    "        'Classics': 'Literary works of lasting value, canonical literature, traditional important works',\n",
    "        'Religion/Spirituality': 'Faith, belief systems, religious practices, spiritual growth, theology',\n",
    "        'Comics/Graphic Novels': 'Illustrated stories, sequential art, comic book format, visual storytelling',\n",
    "        'Cooking/Food': 'Recipes, culinary techniques, food culture, cooking instructions, nutrition',\n",
    "        'Travel': 'Travel guides, destinations, journeys, cultural exploration, adventures abroad',\n",
    "        'Textbook/Education': 'Academic topics, learning materials, educational content, textbooks, theories, concepts',\n",
    "        'Computer Science': 'Programming, algorithms, data structures, computing theory, software development',\n",
    "        'Mathematics': 'Mathematical concepts, equations, proofs, statistical methods, numerical analysis'\n",
    "    }\n",
    "    return genre_descriptions\n",
    "\n",
    "\n",
    "def extract_genres_from_shelves(book_data, genre_map, exclude_shelves):\n",
    "    \"\"\"\n",
    "    Extract genre information from book's popular shelves data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    book_data : dict or pandas Series\n",
    "        Book information containing popular_shelves\n",
    "    genre_map : dict\n",
    "        Dictionary mapping shelf keywords to standardized genre names\n",
    "    exclude_shelves : set\n",
    "        Set of shelf names to exclude\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary of genre names with confidence scores from shelf data\n",
    "    \"\"\"\n",
    "    genre_scores = {}\n",
    "    \n",
    "    shelves = book_data.get('popular_shelves', [])\n",
    "    if not shelves:\n",
    "        return genre_scores\n",
    "    \n",
    "    for shelf in shelves:\n",
    "        shelf_name = shelf.get('name', '').lower()\n",
    "        shelf_count = int(shelf.get('count', 0))\n",
    "        \n",
    "        if shelf_name in exclude_shelves:\n",
    "            continue\n",
    "            \n",
    "        for keyword, genre in genre_map.items():\n",
    "            if keyword == shelf_name or keyword in shelf_name.split('-'):\n",
    "                weight = min(5, shelf_count / 1000) if shelf_count else 1\n",
    "                genre_scores[genre] = genre_scores.get(genre, 0) + weight\n",
    "                break\n",
    "    \n",
    "    return genre_scores\n",
    "\n",
    "\n",
    "def analyze_with_embeddings(title, description, boost=False):\n",
    "    \"\"\"\n",
    "    Analyze book text using sentence embeddings for semantic similarity.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    title : str\n",
    "        Book title\n",
    "    description : str\n",
    "        Book description\n",
    "    boost : bool, optional\n",
    "        Whether to boost confidence scores (default: False)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary of genre names with confidence scores from embedding analysis\n",
    "    \"\"\"\n",
    "    try:\n",
    "        model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        \n",
    "        genre_descriptions = get_genre_embeddings()\n",
    "        genre_texts = [f\"{genre}: {desc}\" for genre, desc in genre_descriptions.items()]\n",
    "        genre_embeddings = model.encode(genre_texts)\n",
    "        \n",
    "        book_text = f\"{title} {description}\"\n",
    "        book_embedding = model.encode([book_text])[0]\n",
    "        \n",
    "        similarities = cosine_similarity([book_embedding], genre_embeddings)[0]\n",
    "        \n",
    "        genre_scores = {}\n",
    "        for i, genre in enumerate(genre_descriptions.keys()):\n",
    "            score = similarities[i] * 10\n",
    "            if boost:\n",
    "                score *= 1.5\n",
    "            if score > 3:\n",
    "                genre_scores[genre] = score\n",
    "        \n",
    "        return genre_scores\n",
    "    except:\n",
    "        return {}\n",
    "\n",
    "\n",
    "def analyze_with_tfidf(title, description, boost=False):\n",
    "    \"\"\"\n",
    "    Analyze book text using TF-IDF for keyword relevance.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    title : str\n",
    "        Book title\n",
    "    description : str\n",
    "        Book description\n",
    "    boost : bool, optional\n",
    "        Whether to boost confidence scores (default: False)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary of genre names with confidence scores from TF-IDF analysis\n",
    "    \"\"\"\n",
    "    genre_scores = {}\n",
    "    \n",
    "    combined_text = (title + \" \" + description).lower()\n",
    "    \n",
    "    genre_patterns = {\n",
    "        'Fantasy': [r'\\bmagic\\b', r'\\bwizard', r'\\bdragon', r'\\bspell', r'\\bkingdom', r'\\bquest\\b'],\n",
    "        'Science Fiction': [r'\\bspace\\b', r'\\balien', r'\\brobot', r'\\bfuture', r'\\btechnology'],\n",
    "        'Mystery/Thriller': [r'\\bmurder', r'\\bdetective', r'\\bcrime', r'\\bmystery', r'\\binvestigation'],\n",
    "        'Romance': [r'\\blove\\b', r'\\bromance', r'\\brelationship', r'\\bheart', r'\\bpassion'],\n",
    "        'Young Adult': [r'\\bteen', r'\\byoung adult', r'\\bcoming of age', r'\\bhigh school'],\n",
    "        'Dystopian': [r'\\bdystopian', r'\\bpost-apocalyptic', r'\\bdictator', r'\\bsurvival', r'\\brebellion'],\n",
    "        'Children\\'s': [r'\\bchildren', r'\\bkid', r'\\bpicture book', r'\\billustrated', r'\\byoung reader'],\n",
    "        'Historical Fiction': [r'\\bhistorical', r'\\bcentury', r'\\bancient', r'\\bera\\b', r'\\bperiod\\b'],\n",
    "        'Textbook/Education': [r'\\btextbook', r'\\bhandbook', r'\\bacademic', r'\\btheory', r'\\bprinciples'],\n",
    "        'Computer Science': [r'\\bprogramming', r'\\balgorithm', r'\\bcomputer', r'\\bsoftware', r'\\bcoding'],\n",
    "        'Mathematics': [r'\\bmathematics', r'\\bstatistics', r'\\bequation', r'\\bnumerical', r'\\btheorem']\n",
    "    }\n",
    "    \n",
    "    for genre, patterns in genre_patterns.items():\n",
    "        score = 0\n",
    "        for pattern in patterns:\n",
    "            matches = len(re.findall(pattern, combined_text))\n",
    "            score += matches * (1.5 if boost else 1.0)\n",
    "        \n",
    "        if score > 0:\n",
    "            genre_scores[genre] = score\n",
    "    \n",
    "    return genre_scores\n",
    "\n",
    "\n",
    "def extract_named_entities(title, description):\n",
    "    \"\"\"\n",
    "    Extract named entities from book text for genre detection.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    title : str\n",
    "        Book title\n",
    "    description : str\n",
    "        Book description\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary of genre names with confidence scores from entity analysis\n",
    "    \"\"\"\n",
    "    try:\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "    except:\n",
    "        try:\n",
    "            spacy.cli.download(\"en_core_web_sm\")\n",
    "            nlp = spacy.load(\"en_core_web_sm\")\n",
    "        except:\n",
    "            return {}\n",
    "    \n",
    "    genre_scores = {}\n",
    "    combined_text = title + \" \" + description\n",
    "    \n",
    "    doc = nlp(combined_text)\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"GPE\" or ent.label_ == \"LOC\":\n",
    "            genre_scores[\"Travel\"] = genre_scores.get(\"Travel\", 0) + 1\n",
    "        elif ent.label_ == \"PERSON\" and len(ent.text.split()) > 1:\n",
    "            genre_scores[\"Biography/Memoir\"] = genre_scores.get(\"Biography/Memoir\", 0) + 1\n",
    "        elif ent.label_ == \"ORG\" and \"university\" in ent.text.lower():\n",
    "            genre_scores[\"Textbook/Education\"] = genre_scores.get(\"Textbook/Education\", 0) + 2\n",
    "    \n",
    "    return genre_scores\n",
    "\n",
    "\n",
    "def detect_specific_genre_patterns(title, description):\n",
    "    \"\"\"\n",
    "    Detect specific genres using pattern matching in title and description.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    title : str\n",
    "        Book title\n",
    "    description : str\n",
    "        Book description\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary of genre names with their confidence scores\n",
    "    \"\"\"\n",
    "    combined_text = (title + \" \" + description).lower()\n",
    "    genre_scores = {}\n",
    "    \n",
    "    dystopian_indicators = [\n",
    "        ('capitol', 'district'), \n",
    "        ('dystopian', 'society'),\n",
    "        ('post-apocalyptic', 'survival'),\n",
    "        ('oppressive', 'government'),\n",
    "        ('totalitarian', 'regime'),\n",
    "        ('controlled', 'society')\n",
    "    ]\n",
    "    for terms in dystopian_indicators:\n",
    "        if all(term in combined_text for term in terms):\n",
    "            genre_scores['Dystopian'] = genre_scores.get('Dystopian', 0) + 5\n",
    "            genre_scores['Young Adult'] = genre_scores.get('Young Adult', 0) + 2\n",
    "    \n",
    "    fantasy_indicators = [\n",
    "        ('magic', 'wizard'),\n",
    "        ('dragon', 'kingdom'),\n",
    "        ('spell', 'quest'),\n",
    "        ('magical', 'creature'),\n",
    "        ('enchanted', 'forest'),\n",
    "        ('sword', 'sorcery')\n",
    "    ]\n",
    "    for terms in fantasy_indicators:\n",
    "        if all(term in combined_text for term in terms):\n",
    "            genre_scores['Fantasy'] = genre_scores.get('Fantasy', 0) + 4\n",
    "    \n",
    "    academic_indicators = [\n",
    "        ('statistical', 'learning'),\n",
    "        ('data', 'mining'),\n",
    "        ('machine', 'learning'),\n",
    "        ('algorithms', 'computational'),\n",
    "        ('mathematics', 'theory'),\n",
    "        ('programming', 'language'),\n",
    "        ('computer', 'science'),\n",
    "        ('neural', 'networks'),\n",
    "        ('artificial', 'intelligence'),\n",
    "        ('physics', 'principles'),\n",
    "        ('engineering', 'design'),\n",
    "        ('bioinformatics', 'genomics'),\n",
    "        ('handbook', 'reference'),\n",
    "        ('analysis', 'methods')\n",
    "    ]\n",
    "    for terms in academic_indicators:\n",
    "        if all(term in combined_text for term in terms):\n",
    "            genre_scores['Textbook/Education'] = genre_scores.get('Textbook/Education', 0) + 6\n",
    "            genre_scores['Science'] = genre_scores.get('Science', 0) + 4\n",
    "    \n",
    "    if 'statistical' in combined_text or 'algorithms' in combined_text or 'mathematics' in combined_text:\n",
    "        if 'Children\\'s' in genre_scores:\n",
    "            del genre_scores['Children\\'s']\n",
    "    \n",
    "    return genre_scores\n",
    "\n",
    "\n",
    "def analyze_metadata(book_data):\n",
    "    \"\"\"\n",
    "    Analyze book metadata for genre signals.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    book_data : dict\n",
    "        Book information with metadata fields\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary of genre names with confidence scores\n",
    "    \"\"\"\n",
    "    metadata_genres = {}\n",
    "    \n",
    "    num_pages = book_data.get('num_pages', 0)\n",
    "    \n",
    "    if 0 < num_pages < 40:\n",
    "        metadata_genres[\"Children's\"] = 4\n",
    "    \n",
    "    if num_pages > 700:\n",
    "        title = str(book_data.get('title', '')).lower()\n",
    "        description = str(book_data.get('description', '')).lower()\n",
    "        combined_text = title + \" \" + description\n",
    "        \n",
    "        academic_terms = ['handbook', 'textbook', 'guide', 'principles', 'introduction to', \n",
    "                        'elements of', 'fundamentals', 'statistics', 'mathematics', \n",
    "                        'engineering', 'biology', 'physics', 'chemistry']\n",
    "        \n",
    "        if any(term in combined_text for term in academic_terms):\n",
    "            metadata_genres['Textbook/Education'] = 5\n",
    "            metadata_genres['Science'] = 3\n",
    "        else:\n",
    "            metadata_genres['Fantasy'] = 2\n",
    "    \n",
    "    title = str(book_data.get('title', '')).lower()\n",
    "    \n",
    "    academic_patterns = [\n",
    "        r'\\bthe \\w+ handbook\\b', \n",
    "        r'\\bprinciples of \\w+\\b',\n",
    "        r'\\belements of \\w+\\b', \n",
    "        r'\\bintroduction to \\w+\\b',\n",
    "        r'\\bfundamentals of \\w+\\b',\n",
    "        r'\\bthe \\w+ companion\\b',\n",
    "        r'\\bguide to \\w+\\b'\n",
    "    ]\n",
    "    \n",
    "    if any(re.search(pattern, title) for pattern in academic_patterns):\n",
    "        metadata_genres['Textbook/Education'] = metadata_genres.get('Textbook/Education', 0) + 5\n",
    "    \n",
    "    return metadata_genres\n",
    "\n",
    "\n",
    "def analyze_similar_books(book_data):\n",
    "    \"\"\"\n",
    "    Analyze similar books for genre information.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    book_data : dict\n",
    "        Book information containing similar_books\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary of genre names with confidence scores\n",
    "    \"\"\"\n",
    "    genre_scores = {}\n",
    "    \n",
    "    similar_books = book_data.get('similar_books', [])\n",
    "    if not similar_books:\n",
    "        return genre_scores\n",
    "    \n",
    "    genre_counts = Counter()\n",
    "    \n",
    "    for book in similar_books:\n",
    "        if 'genres' in book and book['genres']:\n",
    "            for genre in book['genres']:\n",
    "                genre_counts[genre] += 1\n",
    "    \n",
    "    total_books = len(similar_books)\n",
    "    if total_books > 0:\n",
    "        for genre, count in genre_counts.items():\n",
    "            frequency = count / total_books\n",
    "            genre_scores[genre] = frequency * 5\n",
    "    \n",
    "    return genre_scores\n",
    "\n",
    "\n",
    "def combine_all_genre_signals(shelf_genres, nlp_genres, metadata_genres, similar_book_genres, min_confidence):\n",
    "    \"\"\"\n",
    "    Combine genre signals from multiple sources with appropriate weighting.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    shelf_genres : dict\n",
    "        Genres extracted from shelf data\n",
    "    nlp_genres : dict\n",
    "        Genres detected through NLP\n",
    "    metadata_genres : dict\n",
    "        Genres inferred from metadata\n",
    "    similar_book_genres : dict\n",
    "        Genres from similar books\n",
    "    min_confidence : int\n",
    "        Minimum confidence score to include a genre\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    list\n",
    "        Final list of detected genres in order of confidence\n",
    "    \"\"\"\n",
    "    combined_scores = Counter()\n",
    "    \n",
    "    for genre, score in shelf_genres.items():\n",
    "        combined_scores[genre] += score * 3\n",
    "    \n",
    "    for genre, score in nlp_genres.items():\n",
    "        combined_scores[genre] += score * 2\n",
    "    \n",
    "    for genre, score in metadata_genres.items():\n",
    "        combined_scores[genre] += score\n",
    "    \n",
    "    for genre, score in similar_book_genres.items():\n",
    "        combined_scores[genre] += score * 1.5\n",
    "    \n",
    "    sorted_genres = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    final_genres = [genre for genre, score in sorted_genres if score >= min_confidence]\n",
    "    \n",
    "    if not final_genres and sorted_genres:\n",
    "        final_genres = [sorted_genres[0][0]]\n",
    "    \n",
    "    return final_genres\n",
    "\n",
    "\n",
    "def genre_fallback_detection(title, description):\n",
    "    \"\"\"\n",
    "    Last-resort genre detection when all other methods fail.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    title : str\n",
    "        Book title\n",
    "    description : str\n",
    "        Book description\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    list\n",
    "        List of detected genres from fallback method\n",
    "    \"\"\"\n",
    "    simple_genres = []\n",
    "    combined_text = (title + \" \" + description).lower()\n",
    "    \n",
    "    if any(word in combined_text for word in ['magic', 'wizard', 'dragon', 'spell', 'kingdom']):\n",
    "        simple_genres.append('Fantasy')\n",
    "    \n",
    "    if any(word in combined_text for word in ['space', 'alien', 'future', 'technology', 'robot']):\n",
    "        simple_genres.append('Science Fiction')\n",
    "    \n",
    "    if any(word in combined_text for word in ['murder', 'crime', 'detective', 'mystery', 'investigation']):\n",
    "        simple_genres.append('Mystery/Thriller')\n",
    "    \n",
    "    if any(word in combined_text for word in ['love', 'romance', 'relationship', 'heart', 'passion']):\n",
    "        simple_genres.append('Romance')\n",
    "    \n",
    "    if any(word in combined_text for word in ['dystopian', 'oppressive', 'survival', 'rebellion']):\n",
    "        simple_genres.append('Dystopian')\n",
    "    \n",
    "    if any(word in combined_text for word in ['teen', 'young adult', 'coming of age', 'high school']):\n",
    "        simple_genres.append('Young Adult')\n",
    "    \n",
    "    if any(word in combined_text for word in ['children', 'kid', 'picture', 'young reader']):\n",
    "        simple_genres.append('Children\\'s')\n",
    "    \n",
    "    if any(word in combined_text for word in ['textbook', 'theory', 'handbook', 'statistics', 'principles']):\n",
    "        simple_genres.append('Textbook/Education')\n",
    "    \n",
    "    return simple_genres[:2]\n",
    "\n",
    "\n",
    "def test_comprehensive_genre_detection():\n",
    "    \"\"\"\n",
    "    Comprehensive test of genre detection with 10 diverse scenarios.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame containing the test books\n",
    "    \"\"\"\n",
    "    try:\n",
    "        nltk.download('punkt', quiet=True)\n",
    "        nltk.download('stopwords', quiet=True)\n",
    "        nltk.download('wordnet', quiet=True)\n",
    "    except:\n",
    "        print(\"NLTK download failed, but continuing...\")\n",
    "        \n",
    "    test_books = [\n",
    "        {\n",
    "            'scenario': \"Technical book with clear indicators\",\n",
    "            'book_id': 1,\n",
    "            'title': 'The Elements of Statistical Learning',\n",
    "            'average_rating': 4.7,\n",
    "            'ratings_count': 5600,\n",
    "            'description': 'This book describes the important ideas in areas such as data mining, machine learning, and bioinformatics in a statistical framework. It covers many methods including those from supervised learning, strategies for model selection, neural networks, and boosting.',\n",
    "            'num_pages': 745,\n",
    "            'similar_books': [\n",
    "                {'title': 'Pattern Recognition and Machine Learning', 'genres': ['Textbook/Education', 'Computer Science']},\n",
    "                {'title': 'Deep Learning', 'genres': ['Textbook/Education', 'Computer Science']}\n",
    "            ],\n",
    "            'popular_shelves': []\n",
    "        },\n",
    "        {\n",
    "            'scenario': \"Fantasy with rich shelf data\",\n",
    "            'book_id': 2,\n",
    "            'title': 'The Name of the Wind',\n",
    "            'average_rating': 4.55,\n",
    "            'ratings_count': 720000,\n",
    "            'description': 'The intimate narrative of his childhood in a troupe of traveling players, his years spent as a near-feral orphan in a crime-ridden city, his daringly brazen yet successful bid to enter a legendary school of magic, and his life as a fugitive after the murder of a king.',\n",
    "            'num_pages': 662,\n",
    "            'similar_books': [],\n",
    "            'popular_shelves': [\n",
    "                {'count': '12000', 'name': 'fantasy'},\n",
    "                {'count': '6000', 'name': 'fiction'},\n",
    "                {'count': '3000', 'name': 'favorites'},\n",
    "                {'count': '2000', 'name': 'magic'}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'scenario': \"Children's book with minimal description\",\n",
    "            'book_id': 3,\n",
    "            'title': 'Where the Wild Things Are',\n",
    "            'average_rating': 4.22,\n",
    "            'ratings_count': 850000,\n",
    "            'description': 'A story of a young boy named Max.',\n",
    "            'num_pages': 32,\n",
    "            'similar_books': [\n",
    "                {'title': 'Goodnight Moon', 'genres': ['Children\\'s']},\n",
    "                {'title': 'The Very Hungry Caterpillar', 'genres': ['Children\\'s']}\n",
    "            ],\n",
    "            'popular_shelves': []\n",
    "        },\n",
    "        {\n",
    "            'scenario': \"Ambiguous genre with conflicting signals\",\n",
    "            'book_id': 4,\n",
    "            'title': 'The Time Traveler\\'s Wife',\n",
    "            'average_rating': 4.1,\n",
    "            'ratings_count': 1500000,\n",
    "            'description': 'A love story about Henry, a librarian who involuntarily travels through time, and Clare, an artist whose life takes a natural sequential course. Henry and Clare\\'s passionate affair endures across a sea of time and captures them in an impossibly romantic trap.',\n",
    "            'num_pages': 546,\n",
    "            'similar_books': [\n",
    "                {'title': 'The Notebook', 'genres': ['Romance']},\n",
    "                {'title': 'The Night Circus', 'genres': ['Fantasy', 'Romance']}\n",
    "            ],\n",
    "            'popular_shelves': [\n",
    "                {'count': '9000', 'name': 'romance'},\n",
    "                {'count': '7000', 'name': 'science-fiction'},\n",
    "                {'count': '5000', 'name': 'fiction'},\n",
    "                {'count': '3000', 'name': 'time-travel'}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'scenario': \"Non-fiction with specialized topic\",\n",
    "            'book_id': 5,\n",
    "            'title': 'Sapiens: A Brief History of Humankind',\n",
    "            'average_rating': 4.37,\n",
    "            'ratings_count': 720000,\n",
    "            'description': \"From a renowned historian comes a groundbreaking narrative of humanity's creation and evolution that explores the ways in which biology and history have defined us and enhanced our understanding of what it means to be 'human.'\",\n",
    "            'num_pages': 443,\n",
    "            'similar_books': [],\n",
    "            'popular_shelves': [\n",
    "                {'count': '8000', 'name': 'non-fiction'},\n",
    "                {'count': '6000', 'name': 'history'},\n",
    "                {'count': '5000', 'name': 'science'},\n",
    "                {'count': '3000', 'name': 'anthropology'}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'scenario': \"Classic literature with minimal metadata\",\n",
    "            'book_id': 6,\n",
    "            'title': 'Pride and Prejudice',\n",
    "            'average_rating': 4.25,\n",
    "            'ratings_count': 3100000,\n",
    "            'description': 'Since its publication in 1813, Pride and Prejudice has become one of the most popular novels in English literature.',\n",
    "            'num_pages': 279,\n",
    "            'similar_books': [],\n",
    "            'popular_shelves': []\n",
    "        },\n",
    "        {\n",
    "            'scenario': \"Clear dystopian signals in description\",\n",
    "            'book_id': 7,\n",
    "            'title': 'The Giver',\n",
    "            'average_rating': 4.13,\n",
    "            'ratings_count': 1950000,\n",
    "            'description': 'The story follows Jonas, a 12-year-old boy in a seemingly ideal world who is selected to inherit the position of Receiver of Memory, the person who stores all the past memories of the time before Sameness, in case they are ever needed to help make decisions. As Jonas receives the memories, he discovers the terrible truth about his community.',\n",
    "            'num_pages': 179,\n",
    "            'similar_books': [\n",
    "                {'title': 'Divergent', 'genres': ['Young Adult', 'Dystopian']},\n",
    "                {'title': 'The Hunger Games', 'genres': ['Young Adult', 'Dystopian']}\n",
    "            ],\n",
    "            'popular_shelves': []\n",
    "        },\n",
    "        {\n",
    "            'scenario': \"Cooking book with misleading science keyword\",\n",
    "            'book_id': 8,\n",
    "            'title': 'The Science of Good Cooking',\n",
    "            'average_rating': 4.32,\n",
    "            'ratings_count': 8900,\n",
    "            'description': 'In this radical new approach to home cooking, science is the principal tool of the chef. Discover the science behind basic cooking methods like grilling, roasting, and frying, and learn practical recipes that demonstrate each scientific principle.',\n",
    "            'num_pages': 504,\n",
    "            'similar_books': [],\n",
    "            'popular_shelves': [\n",
    "                {'count': '3000', 'name': 'cooking'},\n",
    "                {'count': '2000', 'name': 'food'},\n",
    "                {'count': '1000', 'name': 'reference'}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'scenario': \"Mathematics book with too-short description\",\n",
    "            'book_id': 9,\n",
    "            'title': 'Introduction to Linear Algebra',\n",
    "            'average_rating': 4.1,\n",
    "            'ratings_count': 2100,\n",
    "            'description': 'A comprehensive textbook.',\n",
    "            'num_pages': 584,\n",
    "            'similar_books': [],\n",
    "            'popular_shelves': []\n",
    "        },\n",
    "        {\n",
    "            'scenario': \"Young adult with clear genre indicators\",\n",
    "            'book_id': 10,\n",
    "            'title': 'Twilight',\n",
    "            'average_rating': 3.59,\n",
    "            'ratings_count': 5100000,\n",
    "            'description': 'About three things I was absolutely positive. First, Edward was a vampire. Second, there was a part of him—and I didn\\'t know how dominant that part might be—that thirsted for my blood. And third, I was unconditionally and irrevocably in love with him.',\n",
    "            'num_pages': 498,\n",
    "            'similar_books': [\n",
    "                {'title': 'The Hunger Games', 'genres': ['Young Adult', 'Dystopian']},\n",
    "                {'title': 'City of Bones', 'genres': ['Young Adult', 'Fantasy']}\n",
    "            ],\n",
    "            'popular_shelves': [\n",
    "                {'count': '10000', 'name': 'young-adult'},\n",
    "                {'count': '9000', 'name': 'romance'},\n",
    "                {'count': '7000', 'name': 'fantasy'},\n",
    "                {'count': '6000', 'name': 'vampires'}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    df = pd.DataFrame(test_books)\n",
    "    \n",
    "    print(\"Testing genre detection across 10 diverse scenarios:\\n\")\n",
    "    \n",
    "    for i, book in enumerate(test_books):\n",
    "        print(f\"Scenario {i+1}: {book['scenario']}\")\n",
    "        print(f\"Book: {book['title']}\")\n",
    "        print(f\"Description: {book['description'][:100]}...\")\n",
    "        \n",
    "        genres = detect_book_genre_with_advanced_nlp(book)\n",
    "        \n",
    "        print(f\"Detected genres: {', '.join(genres)}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "    return df\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_comprehensive_genre_detection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4babe42c-0b1a-4f1d-9dca-f7bc149cb701",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50b8de63-2fb7-4a84-819a-8bdc6198fd35",
   "metadata": {},
   "source": [
    "## Detect Age range of book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03def8e9-1173-44cf-a622-ec731ea66935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import string\n",
    "import math\n",
    "import textstat\n",
    "\n",
    "def detect_age_range(book_data):\n",
    "    if book_data.get('popular_shelves') is None:\n",
    "        book_data['popular_shelves'] = []\n",
    "    \n",
    "    title = str(book_data.get('title', ''))\n",
    "    description = str(book_data.get('description', ''))\n",
    "    num_pages = book_data.get('num_pages', 0)\n",
    "    \n",
    "    if isinstance(num_pages, str) and num_pages.strip():\n",
    "        try:\n",
    "            num_pages = int(num_pages)\n",
    "        except ValueError:\n",
    "            num_pages = 0\n",
    "    elif num_pages is None or (isinstance(num_pages, float) and np.isnan(num_pages)):\n",
    "        num_pages = 0\n",
    "        \n",
    "    age_scores = {\n",
    "        '0-5': 0,\n",
    "        '5-10': 0,\n",
    "        '10-15': 0,\n",
    "        '15+': 0\n",
    "    }\n",
    "    \n",
    "    title_lower = title.lower()\n",
    "    description_lower = description.lower()\n",
    "    \n",
    "    # Advanced NLP analysis of title and description\n",
    "    title_complexity = analyze_text_complexity(title)\n",
    "    desc_complexity = analyze_text_complexity(description)\n",
    "    \n",
    "    # Apply title complexity to age scores\n",
    "    if title_complexity < 0.3:\n",
    "        age_scores['0-5'] += 10\n",
    "        age_scores['5-10'] += 5\n",
    "    elif title_complexity < 0.5:\n",
    "        age_scores['5-10'] += 8\n",
    "        age_scores['0-5'] += 4\n",
    "    elif title_complexity < 0.7:\n",
    "        age_scores['10-15'] += 8\n",
    "        age_scores['5-10'] += 4\n",
    "    else:\n",
    "        age_scores['15+'] += 8\n",
    "        age_scores['10-15'] += 4\n",
    "    \n",
    "    # Apply description complexity to age scores\n",
    "    if desc_complexity < 0.3:\n",
    "        age_scores['0-5'] += 12\n",
    "        age_scores['5-10'] += 6\n",
    "    elif desc_complexity < 0.5:\n",
    "        age_scores['5-10'] += 10\n",
    "        age_scores['0-5'] += 5\n",
    "    elif desc_complexity < 0.7:\n",
    "        age_scores['10-15'] += 10\n",
    "        age_scores['5-10'] += 5\n",
    "    else:\n",
    "        age_scores['15+'] += 12\n",
    "        age_scores['10-15'] += 6\n",
    "    \n",
    "    # Sentiment analysis\n",
    "    title_sentiment = analyze_sentiment(title)\n",
    "    desc_sentiment = analyze_sentiment(description)\n",
    "    \n",
    "    # Very positive sentiment often indicates younger children's books\n",
    "    if title_sentiment > 0.6:\n",
    "        age_scores['0-5'] += 8\n",
    "        age_scores['5-10'] += 4\n",
    "    elif title_sentiment > 0.3:\n",
    "        age_scores['5-10'] += 6\n",
    "        age_scores['0-5'] += 3\n",
    "    elif title_sentiment < -0.3:\n",
    "        age_scores['15+'] += 6\n",
    "        age_scores['10-15'] += 3\n",
    "    \n",
    "    if desc_sentiment > 0.6:\n",
    "        age_scores['0-5'] += 6\n",
    "        age_scores['5-10'] += 3\n",
    "    elif desc_sentiment > 0.3:\n",
    "        age_scores['5-10'] += 5\n",
    "        age_scores['0-5'] += 2\n",
    "    elif desc_sentiment < -0.3:\n",
    "        age_scores['15+'] += 5\n",
    "        age_scores['10-15'] += 3\n",
    "    \n",
    "    # POS tag patterns analysis for age appropriateness\n",
    "    pos_patterns = analyze_pos_patterns(description)\n",
    "    for age_range, score in pos_patterns.items():\n",
    "        age_scores[age_range] += score\n",
    "    \n",
    "    board_book_terms = ['board book', 'bedtime', 'goodnight', 'naptime', 'toddler', 'baby', \n",
    "                        'alphabet', 'counting', 'colors', 'shapes', 'lullaby', 'nursery']\n",
    "    \n",
    "    if any(term in title_lower or term in description_lower for term in board_book_terms):\n",
    "        age_scores['0-5'] += 12\n",
    "        age_scores['5-10'] -= 5\n",
    "    \n",
    "    early_reader_terms = ['early reader', 'beginning reader', 'learn to read', 'level reader',\n",
    "                          'first reader', 'step into reading', 'i can read', 'reading level']\n",
    "    \n",
    "    if any(term in title_lower or term in description_lower for term in early_reader_terms):\n",
    "        age_scores['5-10'] += 12\n",
    "        age_scores['0-5'] -= 2\n",
    "    \n",
    "    grade_terms = {\n",
    "        '0-5': ['preschool', 'pre-k', 'kindergarten'],\n",
    "        '5-10': ['grade 1', 'grade 2', 'grade 3', 'grade 4', 'first grade', 'second grade', \n",
    "                'third grade', 'fourth grade', 'fifth grade', 'elementary'],\n",
    "        '10-15': ['grade 5', 'grade 6', 'grade 7', 'grade 8', 'middle school', 'middle-grade', \n",
    "                 'middle grade', 'tween'],\n",
    "        '15+': ['grade 9', 'grade 10', 'grade 11', 'grade 12', 'high school', 'teen', 'young adult',\n",
    "               'ya', 'college', 'university']\n",
    "    }\n",
    "    \n",
    "    for age_range, terms in grade_terms.items():\n",
    "        if any(term in title_lower or term in description_lower for term in terms):\n",
    "            age_scores[age_range] += 10\n",
    "    \n",
    "    if num_pages <= 32:\n",
    "        age_scores['0-5'] += 15\n",
    "        age_scores['5-10'] -= 3\n",
    "    elif 33 <= num_pages <= 48:\n",
    "        age_scores['0-5'] += 10\n",
    "        age_scores['5-10'] += 5\n",
    "    elif 49 <= num_pages <= 80:\n",
    "        age_scores['5-10'] += 12\n",
    "        age_scores['0-5'] -= 2\n",
    "    elif 81 <= num_pages <= 120:\n",
    "        age_scores['5-10'] += 8\n",
    "        age_scores['10-15'] += 4\n",
    "    elif 121 <= num_pages <= 200:\n",
    "        age_scores['10-15'] += 8\n",
    "        age_scores['5-10'] += 4\n",
    "    elif 201 <= num_pages <= 350:\n",
    "        age_scores['10-15'] += 10\n",
    "        age_scores['15+'] += 5\n",
    "    elif num_pages > 350:\n",
    "        age_scores['15+'] += 12\n",
    "        age_scores['10-15'] += 6\n",
    "    \n",
    "    # Combine textstat metrics with more weight\n",
    "    try:\n",
    "        flesch_reading_ease = textstat.flesch_reading_ease(description)\n",
    "        flesch_kincaid_grade = textstat.flesch_kincaid_grade(description)\n",
    "        gunning_fog = textstat.gunning_fog(description)\n",
    "        coleman_liau = textstat.coleman_liau_index(description)\n",
    "        smog = textstat.smog_index(description)\n",
    "        dale_chall = textstat.dale_chall_readability_score(description)\n",
    "        ari = textstat.automated_readability_index(description)\n",
    "        \n",
    "        # Advanced readability score combination\n",
    "        if flesch_reading_ease > 90:\n",
    "            age_scores['0-5'] += 15\n",
    "            age_scores['5-10'] += 5\n",
    "        elif flesch_reading_ease > 80:\n",
    "            age_scores['5-10'] += 12\n",
    "            age_scores['0-5'] += 8\n",
    "        elif flesch_reading_ease > 70:\n",
    "            age_scores['5-10'] += 10\n",
    "            age_scores['10-15'] += 8\n",
    "        elif flesch_reading_ease > 60:\n",
    "            age_scores['10-15'] += 12\n",
    "            age_scores['15+'] += 5\n",
    "        else:\n",
    "            age_scores['15+'] += 15\n",
    "            age_scores['10-15'] += 5\n",
    "        \n",
    "        # Weighted grade level metrics for better discrimination\n",
    "        weighted_grade_level = (\n",
    "            flesch_kincaid_grade * 0.35 + \n",
    "            gunning_fog * 0.2 + \n",
    "            coleman_liau * 0.15 + \n",
    "            smog * 0.15 + \n",
    "            dale_chall * 0.1 + \n",
    "            ari * 0.05\n",
    "        )\n",
    "        \n",
    "        if weighted_grade_level < 1:\n",
    "            age_scores['0-5'] += 15\n",
    "            age_scores['5-10'] -= 2\n",
    "        elif weighted_grade_level < 3:\n",
    "            age_scores['0-5'] += 10\n",
    "            age_scores['5-10'] += 5\n",
    "        elif weighted_grade_level < 5:\n",
    "            age_scores['5-10'] += 12\n",
    "            age_scores['0-5'] += 3\n",
    "        elif weighted_grade_level < 8:\n",
    "            age_scores['10-15'] += 10\n",
    "            age_scores['5-10'] += 5\n",
    "        elif weighted_grade_level < 12:\n",
    "            age_scores['15+'] += 8\n",
    "            age_scores['10-15'] += 12\n",
    "        else:\n",
    "            age_scores['15+'] += 15\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Content theme analysis with increased weight for theme matches\n",
    "    content_themes = analyze_text_themes(title_lower, description_lower)\n",
    "    for age_range, score in content_themes.items():\n",
    "        age_scores[age_range] += score * 1.5\n",
    "    \n",
    "    # Shelf analysis\n",
    "    shelves = book_data.get('popular_shelves', [])\n",
    "    shelf_age_indicators = analyze_shelves_for_age(shelves)\n",
    "    for age_range, score in shelf_age_indicators.items():\n",
    "        age_scores[age_range] += score\n",
    "    \n",
    "    max_score = max(age_scores.values())\n",
    "    final_age_range = max(age_scores.items(), key=lambda x: x[1])[0]\n",
    "    \n",
    "    return final_age_range\n",
    "\n",
    "def analyze_text_complexity(text):\n",
    "    if not text or len(text) < 5:\n",
    "        return 0.5\n",
    "    \n",
    "    try:\n",
    "        sentences = sent_tokenize(text)\n",
    "        words = word_tokenize(text)\n",
    "        \n",
    "        if not sentences or not words:\n",
    "            return 0.5\n",
    "        \n",
    "        avg_sentence_length = len(words) / max(1, len(sentences))\n",
    "        avg_word_length = sum(len(word) for word in words if word.isalpha()) / max(1, len([w for w in words if w.isalpha()]))\n",
    "        \n",
    "        # Calculate lexical diversity (larger vocabulary suggests more complex text)\n",
    "        unique_words = len(set(word.lower() for word in words if word.isalpha()))\n",
    "        lexical_diversity = unique_words / max(1, len([w for w in words if w.isalpha()]))\n",
    "        \n",
    "        # Calculate percentage of complex words (words with 3+ syllables)\n",
    "        complex_words = sum(1 for word in words if word.isalpha() and textstat.syllable_count(word) >= 3)\n",
    "        complex_words_pct = complex_words / max(1, len([w for w in words if w.isalpha()]))\n",
    "        \n",
    "        # Weighted complexity score\n",
    "        complexity_score = (\n",
    "            (avg_sentence_length / 25) * 0.3 + \n",
    "            (avg_word_length / 7) * 0.2 + \n",
    "            lexical_diversity * 0.25 + \n",
    "            complex_words_pct * 0.25\n",
    "        )\n",
    "        \n",
    "        return min(1.0, complexity_score)\n",
    "    except:\n",
    "        return 0.5\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    if not text:\n",
    "        return 0\n",
    "    \n",
    "    try:\n",
    "        positive_words = [\n",
    "            'good', 'great', 'happy', 'love', 'fun', 'wonderful', 'joy', 'exciting', 'adventure',\n",
    "            'magical', 'beautiful', 'sweet', 'friendly', 'amazing', 'delight', 'smile', 'laugh',\n",
    "            'play', 'colorful', 'bright', 'gentle', 'kind', 'nice', 'fantastic', 'awesome'\n",
    "        ]\n",
    "        \n",
    "        negative_words = [\n",
    "            'bad', 'sad', 'angry', 'hate', 'fear', 'dark', 'scary', 'terrible', 'awful', 'horrible',\n",
    "            'cruel', 'evil', 'death', 'fight', 'war', 'cry', 'pain', 'suffer', 'struggle', 'difficult',\n",
    "            'harsh', 'violent', 'grim', 'tragic', 'disaster'\n",
    "        ]\n",
    "        \n",
    "        words = word_tokenize(text.lower())\n",
    "        \n",
    "        pos_count = sum(1 for word in words if word in positive_words)\n",
    "        neg_count = sum(1 for word in words if word in negative_words)\n",
    "        \n",
    "        total_matches = pos_count + neg_count\n",
    "        if total_matches == 0:\n",
    "            return 0\n",
    "        \n",
    "        return (pos_count - neg_count) / total_matches\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def analyze_pos_patterns(text):\n",
    "    try:\n",
    "        age_patterns = {\n",
    "            '0-5': 0,\n",
    "            '5-10': 0,\n",
    "            '10-15': 0,\n",
    "            '15+': 0\n",
    "        }\n",
    "        \n",
    "        # Get POS tags\n",
    "        tokens = word_tokenize(text.lower())\n",
    "        tagged = pos_tag(tokens)\n",
    "        \n",
    "        # Count parts of speech\n",
    "        pos_counts = Counter(tag for word, tag in tagged)\n",
    "        total_tokens = len(tagged)\n",
    "        \n",
    "        if total_tokens == 0:\n",
    "            return age_patterns\n",
    "        \n",
    "        # Simple sentence structure (mainly nouns and verbs) - for young children\n",
    "        simple_structure = (pos_counts.get('NN', 0) + pos_counts.get('NNS', 0) + \n",
    "                           pos_counts.get('VB', 0) + pos_counts.get('VBZ', 0) + \n",
    "                           pos_counts.get('VBP', 0)) / total_tokens\n",
    "        \n",
    "        # Complex sentence markers (conjunctions, relative pronouns, etc.)\n",
    "        complex_markers = (pos_counts.get('IN', 0) + pos_counts.get('WDT', 0) + \n",
    "                          pos_counts.get('WP', 0) + pos_counts.get('WRB', 0)) / total_tokens\n",
    "        \n",
    "        # Advanced language features (adjectives, adverbs, etc.)\n",
    "        advanced_features = (pos_counts.get('JJ', 0) + pos_counts.get('JJR', 0) + \n",
    "                            pos_counts.get('JJS', 0) + pos_counts.get('RB', 0) + \n",
    "                            pos_counts.get('RBR', 0) + pos_counts.get('RBS', 0)) / total_tokens\n",
    "        \n",
    "        # Score assignment based on POS patterns\n",
    "        if simple_structure > 0.6 and complex_markers < 0.1:\n",
    "            age_patterns['0-5'] += 8\n",
    "            age_patterns['5-10'] += 4\n",
    "        elif simple_structure > 0.5 and complex_markers < 0.15:\n",
    "            age_patterns['5-10'] += 7\n",
    "            age_patterns['0-5'] += 3\n",
    "        elif complex_markers > 0.15 and advanced_features > 0.2:\n",
    "            age_patterns['10-15'] += 6\n",
    "            age_patterns['15+'] += 3\n",
    "        elif complex_markers > 0.2 and advanced_features > 0.25:\n",
    "            age_patterns['15+'] += 8\n",
    "            age_patterns['10-15'] += 4\n",
    "        \n",
    "        return age_patterns\n",
    "    except:\n",
    "        return {\n",
    "            '0-5': 0,\n",
    "            '5-10': 0,\n",
    "            '10-15': 0,\n",
    "            '15+': 0\n",
    "        }\n",
    "\n",
    "def analyze_text_themes(title, description):\n",
    "    combined_text = title + \" \" + description\n",
    "    \n",
    "    theme_scores = {\n",
    "        '0-5': 0,\n",
    "        '5-10': 0,\n",
    "        '10-15': 0,\n",
    "        '15+': 0\n",
    "    }\n",
    "    \n",
    "    early_themes = ['sleep', 'bed', 'nap', 'dream', 'moon', 'star', 'night', 'bunny', 'teddy', \n",
    "                    'toy', 'farm', 'animal', 'cat', 'dog', 'duck', 'color', 'zoo', 'mommy', \n",
    "                    'daddy', 'parent', 'bath', 'diaper', 'potty', 'train', 'truck', 'car', \n",
    "                    'alphabet', 'abc', 'number', '123', 'count', 'rhyme']\n",
    "    \n",
    "    elementary_themes = ['school', 'teacher', 'friend', 'adventure', 'fun', 'magic', 'fairy', \n",
    "                        'dragon', 'dinosaur', 'spy', 'detective', 'mystery', 'solve', 'game', \n",
    "                        'play', 'team', 'sport', 'chapter', 'series', 'collect', 'comic', \n",
    "                        'joke', 'funny', 'humor', 'silly', 'prank', 'robot', 'space', 'science']\n",
    "    \n",
    "    middle_themes = ['friend', 'school', 'bully', 'crush', 'team', 'competition', 'journal', \n",
    "                    'diary', 'secret', 'club', 'grow', 'family', 'sibling', 'parent', 'problem', \n",
    "                    'solve', 'quest', 'mission', 'summer', 'camp', 'vacation', 'holiday', \n",
    "                    'fantasy', 'world', 'magic', 'spell', 'creature', 'monster', 'ghost']\n",
    "    \n",
    "    ya_themes = ['love', 'romance', 'relationship', 'kiss', 'boyfriend', 'girlfriend', 'dating', \n",
    "                'death', 'tragedy', 'war', 'battle', 'fight', 'survive', 'future', 'dystopian', \n",
    "                'apocalypse', 'society', 'rebellion', 'government', 'power', 'politics', 'identity', \n",
    "                'struggle', 'college', 'career', 'adult', 'mature', 'violence', 'blood']\n",
    "    \n",
    "    for theme in early_themes:\n",
    "        if theme in combined_text:\n",
    "            theme_scores['0-5'] += 1.5\n",
    "    \n",
    "    for theme in elementary_themes:\n",
    "        if theme in combined_text:\n",
    "            theme_scores['5-10'] += 1.5\n",
    "    \n",
    "    for theme in middle_themes:\n",
    "        if theme in combined_text:\n",
    "            theme_scores['10-15'] += 1.5\n",
    "    \n",
    "    for theme in ya_themes:\n",
    "        if theme in combined_text:\n",
    "            theme_scores['15+'] += 1.5\n",
    "    \n",
    "    return theme_scores\n",
    "\n",
    "def analyze_shelves_for_age(shelves):\n",
    "    shelf_patterns = {\n",
    "        '0-5': ['picture book', 'board book', 'childrens', 'toddler', 'baby', 'preschool', \n",
    "               'bedtime', 'nursery', 'concept book'],\n",
    "        '5-10': ['early reader', 'chapter book', 'childrens', 'kids', 'elementary', 'juvenile', \n",
    "                'easy reader'],\n",
    "        '10-15': ['middle grade', 'middle-grade', 'tween', 'juvenile', 'preteen'],\n",
    "        '15+': ['young adult', 'ya', 'teen', 'high school', 'new adult', 'adult']\n",
    "    }\n",
    "    \n",
    "    shelf_scores = {\n",
    "        '0-5': 0,\n",
    "        '5-10': 0,\n",
    "        '10-15': 0,\n",
    "        '15+': 0\n",
    "    }\n",
    "    \n",
    "    for shelf in shelves:\n",
    "        shelf_name = shelf.get('name', '').lower()\n",
    "        shelf_count = int(shelf.get('count', 0))\n",
    "        \n",
    "        for age_range, patterns in shelf_patterns.items():\n",
    "            if any(pattern in shelf_name for pattern in patterns):\n",
    "                shelf_scores[age_range] += min(12, math.log(shelf_count + 1) * 2)\n",
    "    \n",
    "    return shelf_scores\n",
    "\n",
    "def analyze_books_for_age_ranges(books_df):\n",
    "    result_df = books_df.copy()\n",
    "    age_ranges = []\n",
    "    \n",
    "    for _, book in books_df.iterrows():\n",
    "        age_range = detect_age_range(book)\n",
    "        age_ranges.append(age_range)\n",
    "    \n",
    "    result_df['age_range'] = age_ranges\n",
    "    return result_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_books = [\n",
    "        {\n",
    "            'book_id': 1,\n",
    "            'title': 'Goodnight Moon',\n",
    "            'average_rating': 4.3,\n",
    "            'ratings_count': 310000,\n",
    "            'description': 'In a great green room, tucked away in bed, is a little bunny. \"Goodnight room, goodnight moon.\" And to all the familiar things in the softly lit room—to the picture of the three little bears sitting on chairs, to the clocks and his socks, to the mittens and the kittens, to everything one by one—the little bunny says goodnight.',\n",
    "            'num_pages': 32,\n",
    "            'popular_shelves': [\n",
    "                {'count': '11000', 'name': 'picture-books'},\n",
    "                {'count': '5000', 'name': 'childrens'}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'book_id': 2,\n",
    "            'title': 'The Very Hungry Caterpillar',\n",
    "            'average_rating': 4.35,\n",
    "            'ratings_count': 420000,\n",
    "            'description': 'This is the classic edition of the bestselling story written for the very young. A newly hatched caterpillar eats his way through all kinds of food.',\n",
    "            'num_pages': 24,\n",
    "            'popular_shelves': [\n",
    "                {'count': '9000', 'name': 'picture-books'},\n",
    "                {'count': '4800', 'name': 'childrens'}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'book_id': 3,\n",
    "            'title': 'Brown Bear, Brown Bear, What Do You See?',\n",
    "            'average_rating': 4.25,\n",
    "            'ratings_count': 340000,\n",
    "            'description': 'A big happy frog, a plump purple cat, a handsome blue horse, and a soft yellow duck--all parade across the pages of this delightful book. Children will immediately respond to Eric Carle\\'s flat, boldly colored collages. Combined with Bill Martin\\'s singsong text, they create unforgettable images of these endearing animals.',\n",
    "            'num_pages': 28,\n",
    "            'popular_shelves': [\n",
    "                {'count': '8500', 'name': 'picture-books'},\n",
    "                {'count': '4000', 'name': 'childrens'}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'book_id': 4,\n",
    "            'title': 'Chicka Chicka Boom Boom',\n",
    "            'average_rating': 4.18,\n",
    "            'ratings_count': 180000,\n",
    "            'description': 'In this lively alphabet rhyme, the letters of the alphabet race up the coconut tree. Will there be enough room? Oh, no—Chicka Chicka Boom Boom! The well-known authors of Barn Dance and Knots on a Counting Rope have created a rhythmic alphabet chant that rolls along on waves of fun.',\n",
    "            'num_pages': 36,\n",
    "            'popular_shelves': [\n",
    "                {'count': '6000', 'name': 'picture-books'},\n",
    "                {'count': '3500', 'name': 'childrens'}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'book_id': 5,\n",
    "            'title': 'If You Give a Mouse a Cookie',\n",
    "            'average_rating': 4.32,\n",
    "            'ratings_count': 250000,\n",
    "            'description': 'If a hungry little mouse shows up on your doorstep, you might want to give him a cookie. And if you give him a cookie, he\\'ll ask for a glass of milk. He\\'ll want to look in a mirror to make sure he doesn\\'t have a milk mustache, and then he\\'ll ask for a pair of scissors to give himself a trim....',\n",
    "            'num_pages': 40,\n",
    "            'popular_shelves': [\n",
    "                {'count': '7000', 'name': 'picture-books'},\n",
    "                {'count': '3800', 'name': 'childrens'}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'book_id': 6,\n",
    "            'title': 'Green Eggs and Ham',\n",
    "            'average_rating': 4.29,\n",
    "            'ratings_count': 630000,\n",
    "            'description': '\"Do you like green eggs and ham?\" asks Sam-I-am in this Beginner Book by Dr. Seuss. In a house or with a mouse? In a boat or with a goat? On a train or in a tree? Sam keeps asking persistently. With unmistakable characters and signature rhymes, Dr. Seuss\\'s beloved favorite has cemented its place as a children\\'s classic.',\n",
    "            'num_pages': 62,\n",
    "            'popular_shelves': [\n",
    "                {'count': '12000', 'name': 'childrens'},\n",
    "                {'count': '7500', 'name': 'picture-books'}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'book_id': 7,\n",
    "            'title': 'Magic Tree House #1: Dinosaurs Before Dark',\n",
    "            'average_rating': 4.12,\n",
    "            'ratings_count': 180000,\n",
    "            'description': 'Jack and his younger sister Annie find a magic tree house, which whisks them back to an ancient time zone where they see live dinosaurs.',\n",
    "            'num_pages': 68,\n",
    "            'popular_shelves': [\n",
    "                {'count': '5000', 'name': 'chapter-books'},\n",
    "                {'count': '3800', 'name': 'childrens'}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'book_id': 8,\n",
    "            'title': 'Charlotte\\'s Web',\n",
    "            'average_rating': 4.18,\n",
    "            'ratings_count': 1600000,\n",
    "            'description': 'Some Pig. Humble. Radiant. These are the words in Charlotte\\'s Web, high up in Zuckerman\\'s barn. Charlotte\\'s spiderweb tells of her feelings for a little pig named Wilbur, who simply wants a friend. They also express the love of a girl named Fern, who saved Wilbur\\'s life when he was born the runt of his litter.',\n",
    "            'num_pages': 184,\n",
    "            'popular_shelves': [\n",
    "                {'count': '9000', 'name': 'childrens'},\n",
    "                {'count': '6500', 'name': 'classics'}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'book_id': 9,\n",
    "            'title': 'How to Code: A Step-by-Step Guide to Computer Programming',\n",
    "            'average_rating': 4.32,\n",
    "            'ratings_count': 450,\n",
    "            'description': 'This colorful guide teaches kids the basics of computer programming in a fun and easy-to-follow format. Perfect for children ages 8-12 who want to learn to code, this beginner\\'s guide introduces core coding concepts through easy step-by-step instructions and simple projects.',\n",
    "            'num_pages': 96,\n",
    "            'popular_shelves': [\n",
    "                {'count': '120', 'name': 'educational'},\n",
    "                {'count': '85', 'name': 'computer-science'}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'book_id': 10,\n",
    "            'title': 'The Lion, the Witch and the Wardrobe',\n",
    "            'average_rating': 4.22,\n",
    "            'ratings_count': 2200000,\n",
    "            'description': 'Four adventurous siblings—Peter, Susan, Edmund, and Lucy Pevensie—step through a wardrobe door and into the land of Narnia, a land frozen in eternal winter and enslaved by the power of the White Witch. But when almost all hope is lost, the return of the Great Lion, Aslan, signals a great change... and a great sacrifice.',\n",
    "            'num_pages': 206,\n",
    "            'popular_shelves': [\n",
    "                {'count': '11000', 'name': 'fantasy'},\n",
    "                {'count': '9000', 'name': 'childrens'}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'book_id': 11,\n",
    "            'title': 'Harry Potter and the Sorcerer\\'s Stone',\n",
    "            'average_rating': 4.47,\n",
    "            'ratings_count': 7300000,\n",
    "            'description': 'Harry Potter has no idea how famous he is. That\\'s because he\\'s being raised by his miserable aunt and uncle who are terrified Harry will learn that he\\'s really a wizard, just as his parents were. But everything changes when Harry is summoned to attend an infamous school for wizards, and he begins to discover some clues about his illustrious birthright.',\n",
    "            'num_pages': 309,\n",
    "            'popular_shelves': [\n",
    "                {'count': '25000', 'name': 'fantasy'},\n",
    "                {'count': '18000', 'name': 'young-adult'}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'book_id': 12,\n",
    "            'title': 'Percy Jackson and the Lightning Thief',\n",
    "            'average_rating': 4.25,\n",
    "            'ratings_count': 2200000,\n",
    "            'description': 'Percy Jackson is a good kid, but he can\\'t seem to focus on his schoolwork or control his temper. And lately, being away at boarding school is only getting worse - Percy could have sworn his pre-algebra teacher turned into a monster and tried to kill him. When Percy\\'s mom finds out, she knows it\\'s time that he knew the truth about where he came from, and that he go to the one place he\\'ll be safe.',\n",
    "            'num_pages': 377,\n",
    "            'popular_shelves': [\n",
    "                {'count': '14000', 'name': 'fantasy'},\n",
    "                {'count': '9500', 'name': 'young-adult'}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'book_id': 13,\n",
    "            'title': 'Diary of a Wimpy Kid',\n",
    "            'average_rating': 4.11,\n",
    "            'ratings_count': 680000,\n",
    "            'description': 'Greg Heffley finds himself thrust into a new year and a new school where undersize weaklings share the corridors with kids who are taller, meaner and already shaving. Desperate to prove his new found maturity, which only going up a grade can bring, Greg is happy to have his not-quite-so-cool sidekick, Rowley, along for the ride.',\n",
    "            'num_pages': 217,\n",
    "            'popular_shelves': [\n",
    "                {'count': '5000', 'name': 'middle-grade'},\n",
    "                {'count': '3000', 'name': 'humor'}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'book_id': 14,\n",
    "            'title': 'Wonder',\n",
    "            'average_rating': 4.42,\n",
    "            'ratings_count': 925000,\n",
    "            'description': 'August Pullman was born with a facial difference that, up until now, has prevented him from going to a mainstream school. Starting 5th grade at Beecher Prep, he wants nothing more than to be treated as an ordinary kid but his new classmates cannot get past Auggie\\'s extraordinary face.',\n",
    "            'num_pages': 315,\n",
    "            'popular_shelves': [\n",
    "                {'count': '7500', 'name': 'middle-grade'},\n",
    "                {'count': '5200', 'name': 'realistic-fiction'}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'book_id': 15,\n",
    "            'title': 'Scratch Programming for Middle School Students',\n",
    "            'average_rating': 4.4,\n",
    "            'ratings_count': 180,\n",
    "            'description': 'This guide introduces Scratch programming to middle school students through engaging projects and interactive games. Designed for classroom use or self-study for beginners aged 10-14, this book covers basic concepts and builds to intermediate challenges.',\n",
    "            'num_pages': 145,\n",
    "            'popular_shelves': [\n",
    "                {'count': '35', 'name': 'educational'},\n",
    "                {'count': '25', 'name': 'programming'}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'book_id': 16,\n",
    "            'title': 'The Hunger Games',\n",
    "            'average_rating': 4.32,\n",
    "            'ratings_count': 6100000,\n",
    "            'description': 'In the ruins of a place once known as North America lies the nation of Panem, a shining Capitol surrounded by twelve outlying districts. The Capitol is harsh and cruel and keeps the districts in line by forcing them all to send one boy and one girl between the ages of twelve and eighteen to participate in the annual Hunger Games, a fight to the death on live TV.',\n",
    "            'num_pages': 374,\n",
    "            'popular_shelves': [\n",
    "                {'count': '9000', 'name': 'young-adult'},\n",
    "                {'count': '7000', 'name': 'dystopian'}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'book_id': 17,\n",
    "            'title': 'The Fault in Our Stars',\n",
    "            'average_rating': 4.26,\n",
    "            'ratings_count': 3700000,\n",
    "            'description': 'Despite the tumor-shrinking medical miracle that has bought her a few years, Hazel has never been anything but terminal, her final chapter inscribed upon diagnosis. But when a gorgeous plot twist named Augustus Waters suddenly appears at Cancer Kid Support Group, Hazel\\'s story is about to be completely rewritten.',\n",
    "            'num_pages': 313,\n",
    "            'popular_shelves': [\n",
    "                {'count': '8500', 'name': 'young-adult'},\n",
    "                {'count': '7200', 'name': 'romance'}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'book_id': 18,\n",
    "            'title': 'Six of Crows',\n",
    "            'average_rating': 4.46,\n",
    "            'ratings_count': 350000,\n",
    "            'description': 'Ketterdam: a bustling hub of international trade where anything can be had for the right price—and no one knows that better than criminal prodigy Kaz Brekker. Kaz is offered a chance at a deadly heist that could make him rich beyond his wildest dreams. But he can\\'t pull it off alone. A convict with a thirst for revenge. A sharpshooter who can\\'t walk away from a wager. A runaway with a privileged past. A spy known as the Wraith. A Heartrender using her magic to survive the slums. A thief with a gift for unlikely escapes.',\n",
    "            'num_pages': 465,\n",
    "            'popular_shelves': [\n",
    "                {'count': '7500', 'name': 'fantasy'},\n",
    "                {'count': '6000', 'name': 'young-adult'}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'book_id': 19,\n",
    "            'title': 'Introduction to Algorithms for High School Students',\n",
    "            'average_rating': 4.5,\n",
    "            'ratings_count': 230,\n",
    "            'description': 'A simplified introduction to computer algorithms designed specifically for high school students. This book covers basic searching and sorting algorithms, graphs, and dynamic programming with clear examples and exercises.',\n",
    "            'num_pages': 210,\n",
    "            'popular_shelves': [\n",
    "                {'count': '45', 'name': 'computer-science'},\n",
    "                {'count': '30', 'name': 'textbooks'}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'book_id': 20,\n",
    "            'title': 'Baby\\'s First Animal Board Book',\n",
    "            'average_rating': 4.7,\n",
    "            'ratings_count': 830,\n",
    "            'description': 'This durable board book introduces babies and toddlers to adorable animal friends with bright colors and simple text. Each spread features familiar animals with their names clearly labeled, perfect for early learning and vocabulary development for ages 0-2.',\n",
    "            'num_pages': 12,\n",
    "            'popular_shelves': [\n",
    "                {'count': '150', 'name': 'board-book'},\n",
    "                {'count': '95', 'name': 'baby-books'}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    sample_df = pd.DataFrame(test_books)\n",
    "    \n",
    "    try:\n",
    "        nltk.download('punkt', quiet=True)\n",
    "        nltk.download('stopwords', quiet=True)\n",
    "        nltk.download('wordnet', quiet=True)\n",
    "        nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "    except:\n",
    "        print(\"NLTK download failed, but continuing...\")\n",
    "    \n",
    "    result_df = analyze_books_for_age_ranges(sample_df)\n",
    "    \n",
    "    print(\"\\nBook Age Range Detection Results:\")\n",
    "    print(\"=\" * 80)\n",
    "    for _, book in result_df.iterrows():\n",
    "        print(f\"Title: {book['title']}\")\n",
    "        print(f\"Description: {book['description'][:50]}...\")\n",
    "        print(f\"Pages: {book['num_pages']}\")\n",
    "        print(f\"Detected Age Range: {book['age_range']}\")\n",
    "        print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce506e0d-8462-4682-9513-3466b9b89890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4f2c14-c264-4482-95d1-55ae2de45890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae27e6c3-e2b6-4665-8f05-b14af89a5a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import string\n",
    "import math\n",
    "import textstat\n",
    "\n",
    "def detect_age_range(book_data):\n",
    "    if book_data.get('popular_shelves') is None:\n",
    "        book_data['popular_shelves'] = []\n",
    "    \n",
    "    title = str(book_data.get('title', ''))\n",
    "    description = str(book_data.get('description', ''))\n",
    "    num_pages = book_data.get('num_pages', 0)\n",
    "    \n",
    "    if isinstance(num_pages, str) and num_pages.strip():\n",
    "        try:\n",
    "            num_pages = int(num_pages)\n",
    "        except ValueError:\n",
    "            num_pages = 0\n",
    "    elif num_pages is None or (isinstance(num_pages, float) and np.isnan(num_pages)):\n",
    "        num_pages = 0\n",
    "        \n",
    "    age_scores = {\n",
    "        '0-5': 0,\n",
    "        '5-10': 0,\n",
    "        '10-15': 0,\n",
    "        '15+': 0\n",
    "    }\n",
    "    \n",
    "    title_lower = title.lower()\n",
    "    description_lower = description.lower()\n",
    "    \n",
    "    board_book_terms = ['board book', 'bedtime', 'goodnight', 'naptime', 'toddler', 'baby', \n",
    "                        'alphabet', 'counting', 'colors', 'shapes', 'lullaby', 'nursery']\n",
    "    \n",
    "    if any(term in title_lower or term in description_lower for term in board_book_terms):\n",
    "        age_scores['0-5'] += 12\n",
    "        age_scores['5-10'] -= 5\n",
    "    \n",
    "    early_reader_terms = ['early reader', 'beginning reader', 'learn to read', 'level reader',\n",
    "                          'first reader', 'step into reading', 'i can read', 'reading level']\n",
    "    \n",
    "    if any(term in title_lower or term in description_lower for term in early_reader_terms):\n",
    "        age_scores['5-10'] += 12\n",
    "        age_scores['0-5'] -= 2\n",
    "    \n",
    "    grade_terms = {\n",
    "        '0-5': ['preschool', 'pre-k', 'kindergarten'],\n",
    "        '5-10': ['grade 1', 'grade 2', 'grade 3', 'grade 4', 'first grade', 'second grade', \n",
    "                'third grade', 'fourth grade', 'fifth grade', 'elementary'],\n",
    "        '10-15': ['grade 5', 'grade 6', 'grade 7', 'grade 8', 'middle school', 'middle-grade', \n",
    "                 'middle grade', 'tween'],\n",
    "        '15+': ['grade 9', 'grade 10', 'grade 11', 'grade 12', 'high school', 'teen', 'young adult',\n",
    "               'ya', 'college', 'university']\n",
    "    }\n",
    "    \n",
    "    for age_range, terms in grade_terms.items():\n",
    "        if any(term in title_lower or term in description_lower for term in terms):\n",
    "            age_scores[age_range] += 10\n",
    "    \n",
    "    if num_pages <= 32:\n",
    "        age_scores['0-5'] += 15\n",
    "        age_scores['5-10'] -= 3\n",
    "    elif 33 <= num_pages <= 48:\n",
    "        age_scores['0-5'] += 10\n",
    "        age_scores['5-10'] += 5\n",
    "    elif 49 <= num_pages <= 80:\n",
    "        age_scores['5-10'] += 12\n",
    "        age_scores['0-5'] -= 2\n",
    "    elif 81 <= num_pages <= 120:\n",
    "        age_scores['5-10'] += 8\n",
    "        age_scores['10-15'] += 4\n",
    "    elif 121 <= num_pages <= 200:\n",
    "        age_scores['10-15'] += 8\n",
    "        age_scores['5-10'] += 4\n",
    "    elif 201 <= num_pages <= 350:\n",
    "        age_scores['10-15'] += 10\n",
    "        age_scores['15+'] += 5\n",
    "    elif num_pages > 350:\n",
    "        age_scores['15+'] += 12\n",
    "        age_scores['10-15'] += 6\n",
    "    \n",
    "    try:\n",
    "        flesch_reading_ease = textstat.flesch_reading_ease(description)\n",
    "        flesch_kincaid_grade = textstat.flesch_kincaid_grade(description)\n",
    "        gunning_fog = textstat.gunning_fog(description)\n",
    "        coleman_liau = textstat.coleman_liau_index(description)\n",
    "        smog = textstat.smog_index(description)\n",
    "        \n",
    "        if flesch_reading_ease > 90:\n",
    "            age_scores['0-5'] += 15\n",
    "            age_scores['5-10'] += 5\n",
    "        elif flesch_reading_ease > 80:\n",
    "            age_scores['5-10'] += 12\n",
    "            age_scores['0-5'] += 8\n",
    "        elif flesch_reading_ease > 70:\n",
    "            age_scores['5-10'] += 10\n",
    "            age_scores['10-15'] += 8\n",
    "        elif flesch_reading_ease > 60:\n",
    "            age_scores['10-15'] += 12\n",
    "            age_scores['15+'] += 5\n",
    "        else:\n",
    "            age_scores['15+'] += 15\n",
    "            age_scores['10-15'] += 5\n",
    "        \n",
    "        avg_grade_level = (flesch_kincaid_grade + gunning_fog + coleman_liau + smog) / 4\n",
    "        \n",
    "        if avg_grade_level < 1:\n",
    "            age_scores['0-5'] += 15\n",
    "        elif avg_grade_level < 3:\n",
    "            age_scores['0-5'] += 10\n",
    "            age_scores['5-10'] += 5\n",
    "        elif avg_grade_level < 5:\n",
    "            age_scores['5-10'] += 12\n",
    "            age_scores['0-5'] += 3\n",
    "        elif avg_grade_level < 8:\n",
    "            age_scores['10-15'] += 10\n",
    "            age_scores['5-10'] += 5\n",
    "        elif avg_grade_level < 12:\n",
    "            age_scores['15+'] += 8\n",
    "            age_scores['10-15'] += 12\n",
    "        else:\n",
    "            age_scores['15+'] += 15\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    content_themes = analyze_text_themes(title_lower, description_lower)\n",
    "    for age_range, score in content_themes.items():\n",
    "        age_scores[age_range] += score\n",
    "    \n",
    "    shelves = book_data.get('popular_shelves', [])\n",
    "    shelf_age_indicators = analyze_shelves_for_age(shelves)\n",
    "    for age_range, score in shelf_age_indicators.items():\n",
    "        age_scores[age_range] += score\n",
    "    \n",
    "    max_score = max(age_scores.values())\n",
    "    final_age_range = max(age_scores.items(), key=lambda x: x[1])[0]\n",
    "    \n",
    "    return final_age_range\n",
    "\n",
    "def analyze_text_themes(title, description):\n",
    "    combined_text = title + \" \" + description\n",
    "    \n",
    "    theme_scores = {\n",
    "        '0-5': 0,\n",
    "        '5-10': 0,\n",
    "        '10-15': 0,\n",
    "        '15+': 0\n",
    "    }\n",
    "    \n",
    "    early_themes = ['sleep', 'bed', 'nap', 'dream', 'moon', 'star', 'night', 'bunny', 'teddy', \n",
    "                    'toy', 'farm', 'animal', 'cat', 'dog', 'duck', 'color', 'zoo', 'mommy', \n",
    "                    'daddy', 'parent', 'bath', 'diaper', 'potty', 'train', 'truck', 'car', \n",
    "                    'alphabet', 'abc', 'number', '123', 'count', 'rhyme']\n",
    "    \n",
    "    elementary_themes = ['school', 'teacher', 'friend', 'adventure', 'fun', 'magic', 'fairy', \n",
    "                        'dragon', 'dinosaur', 'spy', 'detective', 'mystery', 'solve', 'game', \n",
    "                        'play', 'team', 'sport', 'chapter', 'series', 'collect', 'comic', \n",
    "                        'joke', 'funny', 'humor', 'silly', 'prank', 'robot', 'space', 'science']\n",
    "    \n",
    "    middle_themes = ['friend', 'school', 'bully', 'crush', 'team', 'competition', 'journal', \n",
    "                    'diary', 'secret', 'club', 'grow', 'family', 'sibling', 'parent', 'problem', \n",
    "                    'solve', 'quest', 'mission', 'summer', 'camp', 'vacation', 'holiday', \n",
    "                    'fantasy', 'world', 'magic', 'spell', 'creature', 'monster', 'ghost']\n",
    "    \n",
    "    ya_themes = ['love', 'romance', 'relationship', 'kiss', 'boyfriend', 'girlfriend', 'dating', \n",
    "                'death', 'tragedy', 'war', 'battle', 'fight', 'survive', 'future', 'dystopian', \n",
    "                'apocalypse', 'society', 'rebellion', 'government', 'power', 'politics', 'identity', \n",
    "                'struggle', 'college', 'career', 'adult', 'mature', 'violence', 'blood']\n",
    "    \n",
    "    for theme in early_themes:\n",
    "        if theme in combined_text:\n",
    "            theme_scores['0-5'] += 1.5\n",
    "    \n",
    "    for theme in elementary_themes:\n",
    "        if theme in combined_text:\n",
    "            theme_scores['5-10'] += 1.5\n",
    "    \n",
    "    for theme in middle_themes:\n",
    "        if theme in combined_text:\n",
    "            theme_scores['10-15'] += 1.5\n",
    "    \n",
    "    for theme in ya_themes:\n",
    "        if theme in combined_text:\n",
    "            theme_scores['15+'] += 1.5\n",
    "    \n",
    "    return theme_scores\n",
    "\n",
    "def analyze_shelves_for_age(shelves):\n",
    "    shelf_patterns = {\n",
    "        '0-5': ['picture book', 'board book', 'childrens', 'toddler', 'baby', 'preschool', \n",
    "               'bedtime', 'nursery', 'concept book'],\n",
    "        '5-10': ['early reader', 'chapter book', 'childrens', 'kids', 'elementary', 'juvenile', \n",
    "                'easy reader'],\n",
    "        '10-15': ['middle grade', 'middle-grade', 'tween', 'juvenile', 'preteen'],\n",
    "        '15+': ['young adult', 'ya', 'teen', 'high school', 'new adult', 'adult']\n",
    "    }\n",
    "    \n",
    "    shelf_scores = {\n",
    "        '0-5': 0,\n",
    "        '5-10': 0,\n",
    "        '10-15': 0,\n",
    "        '15+': 0\n",
    "    }\n",
    "    \n",
    "    for shelf in shelves:\n",
    "        shelf_name = shelf.get('name', '').lower()\n",
    "        shelf_count = int(shelf.get('count', 0))\n",
    "        \n",
    "        for age_range, patterns in shelf_patterns.items():\n",
    "            if any(pattern in shelf_name for pattern in patterns):\n",
    "                shelf_scores[age_range] += min(12, math.log(shelf_count + 1) * 2)\n",
    "    \n",
    "    return shelf_scores\n",
    "\n",
    "def analyze_books_for_age_ranges(books_df):\n",
    "    result_df = books_df.copy()\n",
    "    age_ranges = []\n",
    "    \n",
    "    for _, book in books_df.iterrows():\n",
    "        age_range = detect_age_range(book)\n",
    "        age_ranges.append(age_range)\n",
    "    \n",
    "    result_df['age_range'] = age_ranges\n",
    "    return result_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_books = [\n",
    "        {\n",
    "            'book_id': 1,\n",
    "            'title': 'Goodnight Moon',\n",
    "            'average_rating': 4.3,\n",
    "            'ratings_count': 325000,\n",
    "            'description': 'In a great green room, tucked away in bed, is a little bunny. \"Goodnight room, goodnight moon.\" And to all the familiar things in the softly lit room—to the picture of the three little bears sitting on chairs, to the clocks and his socks, to the mittens and the kittens, to everything one by one—the little bunny says goodnight.',\n",
    "            'num_pages': 32,\n",
    "            'popular_shelves': [\n",
    "                {'count': '12000', 'name': 'picture-book'},\n",
    "                {'count': '8000', 'name': 'childrens'}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'book_id': 2,\n",
    "            'title': 'The Very Hungry Caterpillar',\n",
    "            'average_rating': 4.35,\n",
    "            'ratings_count': 420000,\n",
    "            'description': 'This is the classic edition of the bestselling story written for the very young. A newly hatched caterpillar eats his way through all kinds of food, getting bigger and bigger, until eventually he turns into a beautiful butterfly. One of the most popular picture books of all time, no nursery bookshelf is complete without a copy.',\n",
    "            'num_pages': 24,\n",
    "            'popular_shelves': [\n",
    "                {'count': '14000', 'name': 'picture-book'},\n",
    "                {'count': '9000', 'name': 'childrens'}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'book_id': 3,\n",
    "            'title': 'Brown Bear, Brown Bear, What Do You See?',\n",
    "            'average_rating': 4.25,\n",
    "            'ratings_count': 315000,\n",
    "            'description': 'A big happy frog, a plump purple cat, a handsome blue horse, and a soft yellow duck--all parade across the pages of this delightful book. Children will immediately respond to Eric Carle\\'s flat, boldly colored collages. Combined with Bill Martin\\'s singsong text, they create unforgettable images of these endearing animals.',\n",
    "            'num_pages': 28,\n",
    "            'popular_shelves': [\n",
    "                {'count': '10000', 'name': 'picture-book'},\n",
    "                {'count': '6500', 'name': 'childrens'}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'book_id': 4,\n",
    "            'title': 'Chicka Chicka Boom Boom',\n",
    "            'average_rating': 4.15,\n",
    "            'ratings_count': 250000,\n",
    "            'description': 'In this lively alphabet rhyme, the letters of the alphabet race up the coconut tree. Will there be enough room? Oh, no - Chicka Chicka Boom Boom! The well-known authors of Barn Dance and Knots on a Counting Rope have created a rhythmic alphabet chant that rolls along on waves of fun.',\n",
    "            'num_pages': 36,\n",
    "            'popular_shelves': [\n",
    "                {'count': '8500', 'name': 'picture-book'},\n",
    "                {'count': '5500', 'name': 'childrens'}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'book_id': 5,\n",
    "            'title': 'If You Give a Mouse a Cookie',\n",
    "            'average_rating': 4.32,\n",
    "            'ratings_count': 275000,\n",
    "            'description': 'If a hungry little mouse shows up on your doorstep, you might want to give him a cookie. And if you give him a cookie, he\\'ll ask for a glass of milk. He\\'ll want to look in a mirror to make sure he doesn\\'t have a milk mustache, and then he\\'ll ask for a pair of scissors to give himself a trim....',\n",
    "            'num_pages': 40,\n",
    "            'popular_shelves': [\n",
    "                {'count': '9000', 'name': 'picture-book'},\n",
    "                {'count': '6000', 'name': 'childrens'}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'book_id': 6,\n",
    "            'title': 'Green Eggs and Ham',\n",
    "            'average_rating': 4.3,\n",
    "            'ratings_count': 510000,\n",
    "            'description': '\"Do you like green eggs and ham?\" asks Sam-I-am in this Beginner Book by Dr. Seuss. In a house or with a mouse? In a boat or with a goat? On a train or in a tree? Sam keeps asking persistently. With unmistakable characters and signature rhymes, Dr. Seuss\\'s beloved favorite has cemented its place as a children\\'s classic.',\n",
    "            'num_pages': 62,\n",
    "            'popular_shelves': [\n",
    "                {'count': '11000', 'name': 'childrens'},\n",
    "                {'count': '7000', 'name': 'picture-book'}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'book_id': 7,\n",
    "            'title': 'Magic Tree House #1: Dinosaurs Before Dark',\n",
    "            'average_rating': 4.1,\n",
    "            'ratings_count': 175000,\n",
    "            'description': 'Jack and his younger sister Annie find a magic tree house, which whisks them back to an ancient time zone where they see live dinosaurs. They find a book that tells them about dinosaurs and as they are reading the book, the dinosaurs begin to approach them.',\n",
    "            'num_pages': 68,\n",
    "            'popular_shelves': [\n",
    "                {'count': '4500', 'name': 'chapter-book'},\n",
    "                {'count': '3000', 'name': 'childrens'}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'book_id': 8,\n",
    "            'title': 'Charlotte\\'s Web',\n",
    "            'average_rating': 4.18,\n",
    "            'ratings_count': 1600000,\n",
    "            'description': 'Some Pig. Humble. Radiant. These are the words in Charlotte\\'s Web, high up in Zuckerman\\'s barn. Charlotte\\'s spiderweb tells of her feelings for a little pig named Wilbur, who simply wants a friend. They also express the love of a girl named Fern, who saved Wilbur\\'s life when he was born the runt of his litter.',\n",
    "            'num_pages': 184,\n",
    "            'popular_shelves': [\n",
    "                {'count': '9000', 'name': 'childrens'},\n",
    "                {'count': '6500', 'name': 'classics'}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'book_id': 9,\n",
    "            'title': 'How to Code: A Step-by-Step Guide to Computer Programming',\n",
    "            'average_rating': 4.32,\n",
    "            'ratings_count': 450,\n",
    "            'description': 'This colorful guide teaches kids the basics of computer programming in a fun and easy-to-follow format. Perfect for children ages 8-12 who want to learn to code, this beginner\\'s guide introduces core coding concepts through easy step-by-step instructions and simple projects.',\n",
    "            'num_pages': 96,\n",
    "            'popular_shelves': [\n",
    "                {'count': '120', 'name': 'educational'},\n",
    "                {'count': '85', 'name': 'computer-science'}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'book_id': 10,\n",
    "            'title': 'The Lion, the Witch and the Wardrobe',\n",
    "            'average_rating': 4.22,\n",
    "            'ratings_count': 2200000,\n",
    "            'description': 'Four adventurous siblings—Peter, Susan, Edmund, and Lucy Pevensie—step through a wardrobe door and into the land of Narnia, a land frozen in eternal winter and enslaved by the power of the White Witch. But when almost all hope is lost, the return of the Great Lion, Aslan, signals a great change... and a great sacrifice.',\n",
    "            'num_pages': 206,\n",
    "            'popular_shelves': [\n",
    "                {'count': '11000', 'name': 'fantasy'},\n",
    "                {'count': '9000', 'name': 'childrens'}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'book_id': 11,\n",
    "            'title': 'Harry Potter and the Sorcerer\\'s Stone',\n",
    "            'average_rating': 4.47,\n",
    "            'ratings_count': 7300000,\n",
    "            'description': 'Harry Potter has no idea how famous he is. That\\'s because he\\'s being raised by his miserable aunt and uncle who are terrified Harry will learn that he\\'s really a wizard, just as his parents were. But everything changes when Harry is summoned to attend an infamous school for wizards, and he begins to discover some clues about his illustrious birthright.',\n",
    "            'num_pages': 309,\n",
    "            'popular_shelves': [\n",
    "                {'count': '25000', 'name': 'fantasy'},\n",
    "                {'count': '18000', 'name': 'young-adult'}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'book_id': 12,\n",
    "            'title': 'Percy Jackson and the Lightning Thief',\n",
    "            'average_rating': 4.25,\n",
    "            'ratings_count': 2200000,\n",
    "            'description': 'Percy Jackson is a good kid, but he can\\'t seem to focus on his schoolwork or control his temper. And lately, being away at boarding school is only getting worse - Percy could have sworn his pre-algebra teacher turned into a monster and tried to kill him. When Percy\\'s mom finds out, she knows it\\'s time that he knew the truth about where he came from, and that he go to the one place he\\'ll be safe.',\n",
    "            'num_pages': 377,\n",
    "            'popular_shelves': [\n",
    "                {'count': '14000', 'name': 'fantasy'},\n",
    "                {'count': '9500', 'name': 'young-adult'}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'book_id': 13,\n",
    "            'title': 'Diary of a Wimpy Kid',\n",
    "            'average_rating': 4.11,\n",
    "            'ratings_count': 680000,\n",
    "            'description': 'Greg Heffley finds himself thrust into a new year and a new school where undersize weaklings share the corridors with kids who are taller, meaner and already shaving. Desperate to prove his new found maturity, which only going up a grade can bring, Greg is happy to have his not-quite-so-cool sidekick, Rowley, along for the ride.',\n",
    "            'num_pages': 217,\n",
    "            'popular_shelves': [\n",
    "                {'count': '5000', 'name': 'middle-grade'},\n",
    "                {'count': '3000', 'name': 'humor'}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'book_id': 14,\n",
    "            'title': 'Wonder',\n",
    "            'average_rating': 4.42,\n",
    "            'ratings_count': 925000,\n",
    "            'description': 'August Pullman was born with a facial difference that, up until now, has prevented him from going to a mainstream school. Starting 5th grade at Beecher Prep, he wants nothing more than to be treated as an ordinary kid but his new classmates cannot get past Auggie\\'s extraordinary face.',\n",
    "            'num_pages': 315,\n",
    "            'popular_shelves': [\n",
    "                {'count': '7500', 'name': 'middle-grade'},\n",
    "                {'count': '5200', 'name': 'realistic-fiction'}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'book_id': 15,\n",
    "            'title': 'Scratch Programming for Middle School Students',\n",
    "            'average_rating': 4.4,\n",
    "            'ratings_count': 180,\n",
    "            'description': 'This guide introduces Scratch programming to middle school students through engaging projects and interactive games. Designed for classroom use or self-study for beginners aged 10-14, this book covers basic concepts and builds to intermediate challenges.',\n",
    "            'num_pages': 145,\n",
    "            'popular_shelves': [\n",
    "                {'count': '35', 'name': 'educational'},\n",
    "                {'count': '25', 'name': 'programming'}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'book_id': 16,\n",
    "            'title': 'The Hunger Games',\n",
    "            'average_rating': 4.32,\n",
    "            'ratings_count': 6100000,\n",
    "            'description': 'In the ruins of a place once known as North America lies the nation of Panem, a shining Capitol surrounded by twelve outlying districts. The Capitol is harsh and cruel and keeps the districts in line by forcing them all to send one boy and one girl between the ages of twelve and eighteen to participate in the annual Hunger Games, a fight to the death on live TV.',\n",
    "            'num_pages': 374,\n",
    "            'popular_shelves': [\n",
    "                {'count': '9000', 'name': 'young-adult'},\n",
    "                {'count': '7000', 'name': 'dystopian'}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'book_id': 17,\n",
    "            'title': 'The Fault in Our Stars',\n",
    "            'average_rating': 4.26,\n",
    "            'ratings_count': 3700000,\n",
    "            'description': 'Despite the tumor-shrinking medical miracle that has bought her a few years, Hazel has never been anything but terminal, her final chapter inscribed upon diagnosis. But when a gorgeous plot twist named Augustus Waters suddenly appears at Cancer Kid Support Group, Hazel\\'s story is about to be completely rewritten.',\n",
    "            'num_pages': 313,\n",
    "            'popular_shelves': [\n",
    "                {'count': '8500', 'name': 'young-adult'},\n",
    "                {'count': '7200', 'name': 'romance'}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'book_id': 18,\n",
    "            'title': 'Six of Crows',\n",
    "            'average_rating': 4.46,\n",
    "            'ratings_count': 350000,\n",
    "            'description': 'Ketterdam: a bustling hub of international trade where anything can be had for the right price—and no one knows that better than criminal prodigy Kaz Brekker. Kaz is offered a chance at a deadly heist that could make him rich beyond his wildest dreams. But he can\\'t pull it off alone. A convict with a thirst for revenge. A sharpshooter who can\\'t walk away from a wager. A runaway with a privileged past. A spy known as the Wraith. A Heartrender using her magic to survive the slums. A thief with a gift for unlikely escapes.',\n",
    "            'num_pages': 465,\n",
    "            'popular_shelves': [\n",
    "                {'count': '7500', 'name': 'fantasy'},\n",
    "                {'count': '6000', 'name': 'young-adult'}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'book_id': 19,\n",
    "            'title': 'Introduction to Algorithms for High School Students',\n",
    "            'average_rating': 4.5,\n",
    "            'ratings_count': 230,\n",
    "            'description': 'A simplified introduction to computer algorithms designed specifically for high school students. This book covers basic searching and sorting algorithms, graphs, and dynamic programming with clear examples and exercises.',\n",
    "            'num_pages': 210,\n",
    "            'popular_shelves': [\n",
    "                {'count': '45', 'name': 'computer-science'},\n",
    "                {'count': '30', 'name': 'textbooks'}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'book_id': 20,\n",
    "            'title': 'Baby\\'s First Animal Board Book',\n",
    "            'average_rating': 4.7,\n",
    "            'ratings_count': 830,\n",
    "            'description': 'This durable board book introduces babies and toddlers to adorable animal friends with bright colors and simple text. Each spread features familiar animals with their names clearly labeled, perfect for early learning and vocabulary development for ages 0-2.',\n",
    "            'num_pages': 12,\n",
    "            'popular_shelves': [\n",
    "                {'count': '150', 'name': 'board-book'},\n",
    "                {'count': '95', 'name': 'baby-books'}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    sample_df = pd.DataFrame(test_books)\n",
    "    \n",
    "    try:\n",
    "        nltk.download('punkt', quiet=True)\n",
    "        nltk.download('stopwords', quiet=True)\n",
    "        nltk.download('wordnet', quiet=True)\n",
    "    except:\n",
    "        print(\"NLTK download failed, but continuing...\")\n",
    "    \n",
    "    result_df = analyze_books_for_age_ranges(sample_df)\n",
    "    \n",
    "    print(\"\\nBook Age Range Detection Results:\")\n",
    "    print(\"=\" * 80)\n",
    "    for _, book in result_df.iterrows():\n",
    "        print(f\"Title: {book['title']}\")\n",
    "        print(f\"Description: {book['description'][:50]}...\")\n",
    "        print(f\"Pages: {book['num_pages']}\")\n",
    "        print(f\"Detected Age Range: {book['age_range']}\")\n",
    "        print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840f44d1-17dc-45a4-8be4-223f42145126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce6c141-fada-4a66-adc6-3e5ff12b7943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "356021e4-ff96-4676-bcda-3eaae72ae93b",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ec713d-a2f3-4dc2-b74a-baf81633d018",
   "metadata": {},
   "source": [
    "There are a few ways we can consider hybridizing the approaches. We will now do the ensemble method, which generates two separate recommendation lists and then takes the intersection. Other methods we could consider include (1) weighted hybrid, where a content-based score and a collaborative filtering score is calculated and subsequently combined with a weighted average, or (2) switching hybrid, where content-based filtering is used when the user is new, or when a book has very few ratings, and collaborative filtering is used when a user / book has sufficient history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78684c4a-8aaf-4673-b215-a0dfbe2b39bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#purely for visualization before analysis; to be deleted\n",
    "print(books.head())\n",
    "print(interactions.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e68a4c2-e09e-4ac2-b232-a48f4b15c34c",
   "metadata": {},
   "source": [
    "## Generating Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d47506-f8d9-4212-aef2-ac269d654984",
   "metadata": {},
   "source": [
    "### Content-Based Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36ccb43-6ba0-4bda-8370-2a085071aa46",
   "metadata": {},
   "source": [
    "For Content-Based Filtering, we use **TF-IDF** and **Cosine Similarity** as our core algorithms. \n",
    "\n",
    "**Term Frequency-Inverse Document Frequency (TF-IDF)** uses NLP to identify important words in the `description` attribute of the selected book by evaluating how frequently they appear, relative to the descriptions of all other books in the dataset. Once this is done, we sort the books by how similar they are using **cosine similarity**, which measures the angle between the two vectors (books). If they have a small angle, the books have similar `description` and is thus considered to be similar in content.\n",
    "\n",
    "A better way to imagine this would be if Book A and Book B both have descriptions that talk about \"magic\", \"spells\" and \"wizards\", they would have similar TF-IDF vectors, and thus high cosine similarity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bb9f67-96ea-4397-a332-7384fb9bb3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words = 'english') \n",
    "tfidf_matrix = tfidf.fit_transform(books['description']) #generating TF-IDF matrix\n",
    "\n",
    "def get_content_recommendations (book_id, df = books, tfidf_matrix = tfidf_matrix, top_n = 5):\n",
    "    index = df[df['book_id'] == book_id].index[0]\n",
    "    sim_scores = cosine_similarity(tfidf_matrix[index], tfidf_matrix).flatten() #calculating cosine similarity\n",
    "    top_indices = np.argsort(sim_scores)[::1][1:top_n + 1]\n",
    "    return df.iloc[top_indices][['book_id','title']]\n",
    "\n",
    "similar_books = get_content_recommendations (\"6066812\")\n",
    "print(similar_books)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79039930-ecdd-488e-b4aa-85b7752ee15e",
   "metadata": {},
   "source": [
    "### Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855c2797-a584-4165-b923-c952be9e8c85",
   "metadata": {},
   "source": [
    "We will use K-Nearest Neighbours as an algorithm to perform Collaborative Filtering.\n",
    "\n",
    "Will work on using SVD / Matrix Factorization tomorrow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f0b03b-ec8c-4a0c-a2e2-c7c02f7dc704",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_item_matrix(df): #to create user-item matrix for collaborative filtering\n",
    "    users = interactions['user_id'].nunique()\n",
    "    items = interactions['book_id'].nunique()\n",
    "    \n",
    "    user_mapper = dict(zip(np.unique(interactions['user_id']), list(range(users))))\n",
    "    user_inv_mapper = dict(zip(list(range(users)), np.unique(interactions['user_id'])))\n",
    "    user_index = [user_mapper[i] for i in interactions['user_id']]\n",
    "\n",
    "    \n",
    "    item_mapper = dict(zip(np.unique(interactions['book_id']), list(range(items))))\n",
    "    item_inv_mapper = dict(zip(list(range(items)), np.unique(interactions['book_id'])))\n",
    "    item_index = [item_mapper[i] for i in interactions['book_id']]\n",
    "    \n",
    "    user_item_matrix = csr_matrix((interactions['rating'], (user_index, item_index)), shape = (users, items))\n",
    "    return user_item_matrix, user_mapper, item_mapper, user_inv_mapper, item_inv_mapper\n",
    "\n",
    "user_item_matrix, user_mapper, item_mapper, user_inv_mapper, item_inv_mapper = create_user_item_matrix(interactions)\n",
    "\n",
    "def get_collaborative_recommendations(book_id, books = books, user_item_matrix = user_item_matrix, item_mapper = item_mapper, item_inv_mapper = item_inv_mapper, top_n = 5):\n",
    "    user_item_matrix = user_item_matrix.T\n",
    "    neighbor_ids = []\n",
    "    recommendations = []\n",
    "\n",
    "    item_ind = item_mapper[book_id]\n",
    "    item_vec = user_item_matrix[item_ind]\n",
    "    if isinstance(item_vec, (np.ndarray)):\n",
    "        item_vec = item_vec.reshape(1,-1)\n",
    "\n",
    "    kNN = NearestNeighbors(n_neighbors = top_n + 1, algorithm = \"brute\", metric = \"cosine\") #measuring similarity using K-Nearest-Neighbors\n",
    "    kNN.fit(user_item_matrix)\n",
    "    neighbor = kNN.kneighbors(item_vec, return_distance = False)\n",
    "    for i in range (0, top_n):\n",
    "        n = neighbor.item(i)\n",
    "        neighbor_ids.append(item_inv_mapper[n])\n",
    "    neighbor_ids.pop(0)\n",
    "\n",
    "    for id in neighbor_ids: #retrieving book titles\n",
    "        recommended_books = books.loc[books['book_id'] == id, ['book_id','title']].values[0]\n",
    "        recommendations.append({'book_id': recommended_books[0], 'title': recommended_books[1]})\n",
    "        \n",
    "    recommendations_df = pd.DataFrame(recommendations)\n",
    "    return recommendations_df\n",
    "\n",
    "similar_books = get_collaborative_recommendations (\"6066812\")\n",
    "print(similar_books)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c9c19c-0447-4f7e-9067-7107e76584fb",
   "metadata": {},
   "source": [
    "Havent gotten to it yet, but the two lists of books produced should be combined to generate the final list!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
